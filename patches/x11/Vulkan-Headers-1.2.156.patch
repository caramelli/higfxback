# This file is part of HiGFXback

# requires
REQUIRES="python3-build"

pkg-config --exists --print-errors $REQUIRES || exit 1

# configure
sh ./Configure --prefix /x11

# build
python3 registry/genvk.py -registry registry/vk.xml -o include/vulkan vulkan_beta.h
python3 registry/genvk.py -registry registry/vk.xml -o include/vulkan vulkan_core.h
python3 registry/genvk.py -registry registry/vk.xml -o include/vulkan vulkan_xcb.h
python3 registry/genvk.py -registry registry/vk.xml -o include/vulkan vulkan_xlib.h
python3 registry/genvk.py -registry registry/vk.xml -o include/vulkan vulkan_xlib_xrandr.h

# install
install -d $DESTDIR/x11/include/vulkan
install -m 644 include/vulkan/vk_icd.h $DESTDIR/x11/include/vulkan
install -m 644 include/vulkan/vk_layer.h $DESTDIR/x11/include/vulkan
install -m 644 include/vulkan/vk_platform.h $DESTDIR/x11/include/vulkan
install -m 644 include/vulkan/vk_sdk_platform.h $DESTDIR/x11/include/vulkan
install -m 644 include/vulkan/vulkan.h $DESTDIR/x11/include/vulkan
install -m 644 include/vulkan/vulkan_beta.h $DESTDIR/x11/include/vulkan
install -m 644 include/vulkan/vulkan_core.h $DESTDIR/x11/include/vulkan
install -m 644 include/vulkan/vulkan_xcb.h $DESTDIR/x11/include/vulkan
install -m 644 include/vulkan/vulkan_xlib.h $DESTDIR/x11/include/vulkan
install -m 644 include/vulkan/vulkan_xlib_xrandr.h $DESTDIR/x11/include/vulkan
install -d $DESTDIR/x11/lib/pkgconfig
install -m 644 vulkan-registry.pc $DESTDIR/x11/lib/pkgconfig
install -d $DESTDIR/x11/share/vulkan/registry
install -m 644 registry/vk.xml $DESTDIR/x11/share/vulkan/registry

# build.pc
install -d $DESTDIR/x11/share/pkgconfig
cat > $DESTDIR/x11/share/pkgconfig/vulkan-headers-build.pc << EOF
Name: Vulkan-Headers
Version: 1.2.156
Description: Vulkan API Headers
Requires: $REQUIRES

devel=\\
/x11/include/vulkan/vk_icd.h \\
/x11/include/vulkan/vk_layer.h \\
/x11/include/vulkan/vk_platform.h \\
/x11/include/vulkan/vk_sdk_platform.h \\
/x11/include/vulkan/vulkan.h \\
/x11/include/vulkan/vulkan_beta.h \\
/x11/include/vulkan/vulkan_core.h \\
/x11/include/vulkan/vulkan_xcb.h \\
/x11/include/vulkan/vulkan_xlib.h \\
/x11/include/vulkan/vulkan_xlib_xrandr.h \\
/x11/lib/pkgconfig/vulkan-registry.pc \\
/x11/share/vulkan/registry/vk.xml
EOF

exit
--- Vulkan-Headers-1.2.156.orig/CMakeLists.txt
+++ Vulkan-Headers-1.2.156/CMakeLists.txt
@@ -20,8 +20,7 @@
 
 cmake_minimum_required(VERSION 3.10.2)
 
-# NONE = this project has no language toolchain requirement.
-project(Vulkan-Headers NONE)
+project(Vulkan-Headers)
 
 # User-interface declarations ----------------------------------------------------------------------------------------------------
 # This section contains variables that affect development GUIs (e.g. CMake GUI and IDEs), such as option(), folders, and variables
@@ -48,6 +47,11 @@
 install(DIRECTORY "${CMAKE_CURRENT_SOURCE_DIR}/include/vulkan" DESTINATION ${CMAKE_INSTALL_INCLUDEDIR})
 install(DIRECTORY "${CMAKE_CURRENT_SOURCE_DIR}/registry" DESTINATION ${CMAKE_INSTALL_DATADIR}/vulkan)
 
+configure_file("${CMAKE_CURRENT_SOURCE_DIR}/registry/vulkan-registry.pc.in"
+               "${CMAKE_CURRENT_BINARY_DIR}/vulkan-registry.pc"
+               @ONLY)
+install(FILES "${CMAKE_CURRENT_BINARY_DIR}/vulkan-registry.pc" DESTINATION ${CMAKE_INSTALL_LIBDIR}/pkgconfig)
+
 # uninstall target
 if(NOT TARGET uninstall)
     configure_file("${CMAKE_CURRENT_SOURCE_DIR}/cmake/cmake_uninstall.cmake.in"
--- Vulkan-Headers-1.2.156.orig/Configure
+++ Vulkan-Headers-1.2.156/Configure
@@ -0,0 +1,22 @@
+#!/bin/sh
+
+PREFIX=/usr/local
+
+while : ; do
+  case "$1" in
+    "")
+      break
+    ;;
+    --prefix)
+      PREFIX=$2
+      shift
+    ;;
+    *)
+      echo Unknown option \"$1\".
+      exit 1
+    ;;
+  esac
+  shift
+done
+
+sed "/^prefix/s|=.*|=$PREFIX|" registry/vulkan-registry.pc.in > vulkan-registry.pc
--- Vulkan-Headers-1.2.156.orig/registry/docgenerator.py
+++ Vulkan-Headers-1.2.156/registry/docgenerator.py
@@ -0,0 +1,450 @@
+#!/usr/bin/python3 -i
+#
+# Copyright (c) 2013-2020 The Khronos Group Inc.
+#
+# SPDX-License-Identifier: Apache-2.0
+
+from pathlib import Path
+
+from generator import GeneratorOptions, OutputGenerator, noneStr, write
+
+ENUM_TABLE_PREFIX = """
+[cols=",",options="header",]
+|=======================================================================
+|Enum |Description"""
+
+ENUM_TABLE_SUFFIX = """|======================================================================="""
+
+FLAG_BLOCK_PREFIX = """.Flag Descriptions
+****"""
+
+FLAG_BLOCK_SUFFIX = """****"""
+
+
+class DocGeneratorOptions(GeneratorOptions):
+    """DocGeneratorOptions - subclass of GeneratorOptions for
+    generating declaration snippets for the spec.
+
+    Shares many members with CGeneratorOptions, since
+    both are writing C-style declarations."""
+
+    def __init__(self,
+                 prefixText="",
+                 apicall='',
+                 apientry='',
+                 apientryp='',
+                 indentFuncProto=True,
+                 indentFuncPointer=False,
+                 alignFuncParam=0,
+                 secondaryInclude=False,
+                 expandEnumerants=True,
+                 extEnumerantAdditions=False,
+                 extEnumerantFormatString=" (Added by the {} extension)",
+                 **kwargs):
+        """Constructor.
+
+        Since this generator outputs multiple files at once,
+        the filename is just a "stamp" to indicate last generation time.
+
+        Shares many parameters/members with CGeneratorOptions, since
+        both are writing C-style declarations:
+
+        - prefixText - list of strings to prefix generated header with
+        (usually a copyright statement + calling convention macros).
+        - apicall - string to use for the function declaration prefix,
+        such as APICALL on Windows.
+        - apientry - string to use for the calling convention macro,
+        in typedefs, such as APIENTRY.
+        - apientryp - string to use for the calling convention macro
+        in function pointer typedefs, such as APIENTRYP.
+        - indentFuncProto - True if prototype declarations should put each
+        parameter on a separate line
+        - indentFuncPointer - True if typedefed function pointers should put each
+        parameter on a separate line
+        - alignFuncParam - if nonzero and parameters are being put on a
+        separate line, align parameter names at the specified column
+
+        Additional parameters/members:
+
+        - expandEnumerants - if True, add BEGIN/END_RANGE macros in enumerated
+        type declarations
+        - secondaryInclude - if True, add secondary (no xref anchor) versions
+        of generated files
+        - extEnumerantAdditions - if True, include enumerants added by extensions
+        in comment tables for core enumeration types.
+        - extEnumerantFormatString - A format string for any additional message for
+        enumerants from extensions if extEnumerantAdditions is True. The correctly-
+        marked-up extension name will be passed.
+        """
+        GeneratorOptions.__init__(self, **kwargs)
+        self.prefixText = prefixText
+        """list of strings to prefix generated header with (usually a copyright statement + calling convention macros)."""
+
+        self.apicall = apicall
+        """string to use for the function declaration prefix, such as APICALL on Windows."""
+
+        self.apientry = apientry
+        """string to use for the calling convention macro, in typedefs, such as APIENTRY."""
+
+        self.apientryp = apientryp
+        """string to use for the calling convention macro in function pointer typedefs, such as APIENTRYP."""
+
+        self.indentFuncProto = indentFuncProto
+        """True if prototype declarations should put each parameter on a separate line"""
+
+        self.indentFuncPointer = indentFuncPointer
+        """True if typedefed function pointers should put each parameter on a separate line"""
+
+        self.alignFuncParam = alignFuncParam
+        """if nonzero and parameters are being put on a separate line, align parameter names at the specified column"""
+
+        self.secondaryInclude = secondaryInclude
+        """if True, add secondary (no xref anchor) versions of generated files"""
+
+        self.expandEnumerants = expandEnumerants
+        """if True, add BEGIN/END_RANGE macros in enumerated type declarations"""
+
+        self.extEnumerantAdditions = extEnumerantAdditions
+        """if True, include enumerants added by extensions in comment tables for core enumeration types."""
+
+        self.extEnumerantFormatString = extEnumerantFormatString
+        """A format string for any additional message for
+        enumerants from extensions if extEnumerantAdditions is True. The correctly-
+        marked-up extension name will be passed."""
+
+
+class DocOutputGenerator(OutputGenerator):
+    """DocOutputGenerator - subclass of OutputGenerator.
+
+    Generates AsciiDoc includes with C-language API interfaces, for reference
+    pages and the corresponding specification. Similar to COutputGenerator,
+    but each interface is written into a different file as determined by the
+    options, only actual C types are emitted, and none of the boilerplate
+    preprocessor code is emitted."""
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+        # Keep track of all extension numbers
+        self.extension_numbers = set()
+
+    def beginFile(self, genOpts):
+        OutputGenerator.beginFile(self, genOpts)
+
+        # This should be a separate conventions property rather than an
+        # inferred type name pattern for different APIs.
+        self.result_type = genOpts.conventions.type_prefix + "Result"
+
+    def endFile(self):
+        OutputGenerator.endFile(self)
+
+    def beginFeature(self, interface, emit):
+        # Start processing in superclass
+        OutputGenerator.beginFeature(self, interface, emit)
+
+        # Decide if we're in a core <feature> or an <extension>
+        self.in_core = (interface.tag == 'feature')
+
+        # Verify that each <extension> has a unique number during doc
+        # generation
+        # TODO move this to consistency_tools
+        if not self.in_core:
+            extension_number = interface.get('number')
+            if extension_number is not None and extension_number != "0":
+                if extension_number in self.extension_numbers:
+                    self.logMsg('error', 'Duplicate extension number ', extension_number, ' detected in feature ', interface.get('name'), '\n')
+                    exit(1)
+                else:
+                    self.extension_numbers.add(extension_number)
+
+    def endFeature(self):
+        # Finish processing in superclass
+        OutputGenerator.endFeature(self)
+
+    def genRequirements(self, name, mustBeFound = True):
+        """Generate text showing what core versions and extensions introduce
+        an API. This relies on the map in api.py, which may be loaded at
+        runtime into self.apidict. If not present, no message is
+        generated.
+
+        - name - name of the API
+        - mustBeFound - If True, when requirements for 'name' cannot be
+          determined, a warning comment is generated.
+        """
+
+        if self.apidict:
+            if name in self.apidict.requiredBy:
+                features = []
+                for (base,dependency) in self.apidict.requiredBy[name]:
+                    if dependency is not None:
+                        features.append('{} with {}'.format(base, dependency))
+                    else:
+                        features.append(base)
+                return '// Provided by {}\n'.format(', '.join(features))
+            else:
+                if mustBeFound:
+                    self.logMsg('warn', 'genRequirements: API {} not found'.format(name))
+                return ''
+        else:
+            # No API dictionary available, return nothing
+            return ''
+
+    def writeInclude(self, directory, basename, contents):
+        """Generate an include file.
+
+        - directory - subdirectory to put file in
+        - basename - base name of the file
+        - contents - contents of the file (Asciidoc boilerplate aside)"""
+        # Create subdirectory, if needed
+        directory = self.genOpts.directory + '/' + directory
+        self.makeDir(directory)
+
+        # Create file
+        filename = directory + '/' + basename + '.txt'
+        self.logMsg('diag', '# Generating include file:', filename)
+        fp = open(filename, 'w', encoding='utf-8')
+
+        # Asciidoc anchor
+        write(self.genOpts.conventions.warning_comment, file=fp)
+        write('[[{0},{0}]]'.format(basename), file=fp)
+
+        if self.genOpts.conventions.generate_index_terms:
+            index_terms = []
+            if basename.startswith(self.conventions.command_prefix):
+                index_terms.append(basename[2:] + " (function)")
+            elif basename.startswith(self.conventions.type_prefix):
+                index_terms.append(basename[2:] + " (type)")
+            elif basename.startswith(self.conventions.api_prefix):
+                index_terms.append(basename[len(self.conventions.api_prefix):] + " (define)")
+            index_terms.append(basename)
+            write('indexterm:[{}]'.format(','.join(index_terms)), file=fp)
+
+        write('[source,c++]', file=fp)
+        write('----', file=fp)
+        write(contents, file=fp)
+        write('----', file=fp)
+        fp.close()
+
+        if self.genOpts.secondaryInclude:
+            # Create secondary no cross-reference include file
+            filename = directory + '/' + basename + '.no-xref.txt'
+            self.logMsg('diag', '# Generating include file:', filename)
+            fp = open(filename, 'w', encoding='utf-8')
+
+            # Asciidoc anchor
+            write(self.genOpts.conventions.warning_comment, file=fp)
+            write('// Include this no-xref version without cross reference id for multiple includes of same file', file=fp)
+            write('[source,c++]', file=fp)
+            write('----', file=fp)
+            write(contents, file=fp)
+            write('----', file=fp)
+            fp.close()
+
+    def writeTable(self, basename, values):
+        """Output a table of enumerants."""
+        directory = Path(self.genOpts.directory) / 'enums'
+        self.makeDir(str(directory))
+
+        filename = str(directory / '{}.comments.txt'.format(basename))
+        self.logMsg('diag', '# Generating include file:', filename)
+
+        with open(filename, 'w', encoding='utf-8') as fp:
+            write(self.conventions.warning_comment, file=fp)
+            write(ENUM_TABLE_PREFIX, file=fp)
+
+            for data in values:
+                write("|ename:{}".format(data['name']), file=fp)
+                write("|{}".format(data['comment']), file=fp)
+
+            write(ENUM_TABLE_SUFFIX, file=fp)
+
+    def writeFlagBox(self, basename, values):
+        """Output a box of flag bit comments."""
+        directory = Path(self.genOpts.directory) / 'enums'
+        self.makeDir(str(directory))
+
+        filename = str(directory / '{}.comments.txt'.format(basename))
+        self.logMsg('diag', '# Generating include file:', filename)
+
+        with open(filename, 'w', encoding='utf-8') as fp:
+            write(self.conventions.warning_comment, file=fp)
+            write(FLAG_BLOCK_PREFIX, file=fp)
+
+            for data in values:
+                write("* ename:{} -- {}".format(data['name'],
+                                                data['comment']),
+                      file=fp)
+
+            write(FLAG_BLOCK_SUFFIX, file=fp)
+
+    def genType(self, typeinfo, name, alias):
+        """Generate type."""
+        OutputGenerator.genType(self, typeinfo, name, alias)
+        typeElem = typeinfo.elem
+        # If the type is a struct type, traverse the embedded <member> tags
+        # generating a structure. Otherwise, emit the tag text.
+        category = typeElem.get('category')
+
+        if category in ('struct', 'union'):
+            # If the type is a struct type, generate it using the
+            # special-purpose generator.
+            self.genStruct(typeinfo, name, alias)
+        else:
+            body = self.genRequirements(name)
+            if alias:
+                # If the type is an alias, just emit a typedef declaration
+                body += 'typedef ' + alias + ' ' + name + ';\n'
+                self.writeInclude(OutputGenerator.categoryToPath[category],
+                                  name, body)
+            else:
+                # Replace <apientry /> tags with an APIENTRY-style string
+                # (from self.genOpts). Copy other text through unchanged.
+                # If the resulting text is an empty string, don't emit it.
+                body += noneStr(typeElem.text)
+                for elem in typeElem:
+                    if elem.tag == 'apientry':
+                        body += self.genOpts.apientry + noneStr(elem.tail)
+                    else:
+                        body += noneStr(elem.text) + noneStr(elem.tail)
+
+                if body:
+                    if category in OutputGenerator.categoryToPath:
+                        self.writeInclude(OutputGenerator.categoryToPath[category],
+                                          name, body + '\n')
+                    else:
+                        self.logMsg('diag', '# NOT writing include file for type:',
+                                    name, '- bad category: ', category)
+                else:
+                    self.logMsg('diag', '# NOT writing empty include file for type', name)
+
+    def genStruct(self, typeinfo, typeName, alias):
+        """Generate struct."""
+        OutputGenerator.genStruct(self, typeinfo, typeName, alias)
+
+        typeElem = typeinfo.elem
+
+        body = self.genRequirements(typeName)
+        if alias:
+            body += 'typedef ' + alias + ' ' + typeName + ';\n'
+        else:
+            body += 'typedef ' + typeElem.get('category') + ' ' + typeName + ' {\n'
+
+            targetLen = self.getMaxCParamTypeLength(typeinfo)
+            for member in typeElem.findall('.//member'):
+                body += self.makeCParamDecl(member, targetLen + 4)
+                body += ';\n'
+            body += '} ' + typeName + ';'
+
+        self.writeInclude('structs', typeName, body)
+
+    def genEnumTable(self, groupinfo, groupName):
+        """Generate tables of enumerant values and short descriptions from
+        the XML."""
+
+        values = []
+        got_comment = False
+        missing_comments = []
+        for elem in groupinfo.elem.findall('enum'):
+            if not elem.get('required'):
+                continue
+            name = elem.get('name')
+
+            data = {
+                'name': name,
+            }
+
+            (numVal, strVal) = self.enumToValue(elem, True)
+            data['value'] = numVal
+
+            extname = elem.get('extname')
+
+            added_by_extension_to_core = (extname is not None and self.in_core)
+            if added_by_extension_to_core and not self.genOpts.extEnumerantAdditions:
+                # We're skipping such values
+                continue
+
+            comment = elem.get('comment')
+            if comment:
+                got_comment = True
+            elif name.endswith('_UNKNOWN') and numVal == 0:
+                # This is a placeholder for 0-initialization to be clearly invalid.
+                # Just skip this silently
+                continue
+            else:
+                # Skip but record this in case it's an odd-one-out missing a comment.
+                missing_comments.append(name)
+                continue
+
+            if added_by_extension_to_core and self.genOpts.extEnumerantFormatString:
+                # Add a note to the comment
+                comment += self.genOpts.extEnumerantFormatString.format(
+                    self.conventions.formatExtension(extname))
+
+            data['comment'] = comment
+            values.append(data)
+
+        if got_comment:
+            # If any had a comment, output it.
+
+            if missing_comments:
+                self.logMsg('warn', 'The following values for', groupName,
+                            'were omitted from the table due to missing comment attributes:',
+                            ', '.join(missing_comments))
+
+            group_type = groupinfo.elem.get('type')
+            if groupName == self.result_type:
+                # Split this into success and failure
+                self.writeTable(groupName + '.success',
+                                (data for data in values
+                                 if data['value'] >= 0))
+                self.writeTable(groupName + '.error',
+                                (data for data in values
+                                 if data['value'] < 0))
+            elif group_type == 'bitmask':
+                self.writeFlagBox(groupName, values)
+            elif group_type == 'enum':
+                self.writeTable(groupName, values)
+            else:
+                raise RuntimeError("Unrecognized enums type: " + str(group_type))
+
+    def genGroup(self, groupinfo, groupName, alias):
+        """Generate group (e.g. C "enum" type)."""
+        OutputGenerator.genGroup(self, groupinfo, groupName, alias)
+
+        body = self.genRequirements(groupName)
+        if alias:
+            # If the group name is aliased, just emit a typedef declaration
+            # for the alias.
+            body += 'typedef ' + alias + ' ' + groupName + ';\n'
+        else:
+            expand = self.genOpts.expandEnumerants
+            (_, enumbody) = self.buildEnumCDecl(expand, groupinfo, groupName)
+            body += enumbody
+            if self.genOpts.conventions.generate_enum_table:
+                self.genEnumTable(groupinfo, groupName)
+
+        self.writeInclude('enums', groupName, body)
+
+    def genEnum(self, enuminfo, name, alias):
+        """Generate enumerant."""
+        OutputGenerator.genEnum(self, enuminfo, name, alias)
+        self.logMsg('diag', '# NOT writing compile-time constant', name)
+
+    def genCmd(self, cmdinfo, name, alias):
+        "Generate command."
+        OutputGenerator.genCmd(self, cmdinfo, name, alias)
+
+        return_type = cmdinfo.elem.find('proto/type')
+        if self.genOpts.conventions.requires_error_validation(return_type):
+            # This command returns an API result code, so check that it
+            # returns at least the required errors.
+            # TODO move this to consistency_tools
+            required_errors = set(self.genOpts.conventions.required_errors)
+            errorcodes = cmdinfo.elem.get('errorcodes').split(',')
+            if not required_errors.issubset(set(errorcodes)):
+                self.logMsg('error', 'Missing required error code for command: ', name, '\n')
+                exit(1)
+
+        body = self.genRequirements(name)
+        decls = self.makeCDecls(cmdinfo.elem)
+        body += decls[0]
+        self.writeInclude('protos', name, body)
--- Vulkan-Headers-1.2.156.orig/registry/extensionmetadocgenerator.py
+++ Vulkan-Headers-1.2.156/registry/extensionmetadocgenerator.py
@@ -0,0 +1,636 @@
+#!/usr/bin/python3 -i
+#
+# Copyright (c) 2013-2020 The Khronos Group Inc.
+#
+# SPDX-License-Identifier: Apache-2.0
+
+import re
+import sys
+from functools import total_ordering
+from generator import GeneratorOptions, OutputGenerator, regSortFeatures, write
+
+class ExtensionMetaDocGeneratorOptions(GeneratorOptions):
+    """ExtensionMetaDocGeneratorOptions - subclass of GeneratorOptions.
+
+    Represents options during extension metainformation generation for Asciidoc"""
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+
+EXT_NAME_DECOMPOSE_RE = re.compile(r'[A-Z]+_(?P<tag>[A-Z]+)_(?P<name>[\w_]+)')
+
+
+@total_ordering
+class Extension:
+    def __init__(self,
+                 generator, # needed for logging and API conventions
+                 filename,
+                 name,
+                 number,
+                 ext_type,
+                 requires,
+                 requiresCore,
+                 contact,
+                 promotedTo,
+                 deprecatedBy,
+                 obsoletedBy,
+                 provisional,
+                 revision,
+                 specialuse ):
+        self.generator = generator
+        self.conventions = generator.genOpts.conventions
+        self.filename = filename
+        self.name = name
+        self.number = number
+        self.ext_type = ext_type
+        self.requires = requires
+        self.requiresCore = requiresCore
+        self.contact = contact
+        self.promotedTo = promotedTo
+        self.deprecatedBy = deprecatedBy
+        self.obsoletedBy = obsoletedBy
+        self.provisional = provisional
+        self.revision = revision
+        self.specialuse = specialuse
+
+        self.deprecationType = None
+        self.supercedingAPIVersion = None
+        self.supercedingExtension = None
+
+        if self.promotedTo is not None and self.deprecatedBy is not None and self.obsoletedBy is not None:
+            self.generator.logMsg('warn', 'All \'promotedto\', \'deprecatedby\' and \'obsoletedby\' attributes used on extension ' + self.name + '! Ignoring \'promotedto\' and \'deprecatedby\'.')
+        elif self.promotedTo is not None and self.deprecatedBy is not None:
+            self.generator.logMsg('warn', 'Both \'promotedto\' and \'deprecatedby\' attributes used on extension ' + self.name + '! Ignoring \'deprecatedby\'.')
+        elif self.promotedTo is not None and self.obsoletedBy is not None:
+            self.generator.logMsg('warn', 'Both \'promotedto\' and \'obsoletedby\' attributes used on extension ' + self.name + '! Ignoring \'promotedto\'.')
+        elif self.deprecatedBy is not None and self.obsoletedBy is not None:
+            self.generator.logMsg('warn', 'Both \'deprecatedby\' and \'obsoletedby\' attributes used on extension ' + self.name + '! Ignoring \'deprecatedby\'.')
+
+        supercededBy = None
+        if self.promotedTo is not None:
+            self.deprecationType = 'promotion'
+            supercededBy = promotedTo
+        elif self.deprecatedBy is not None:
+            self.deprecationType = 'deprecation'
+            supercededBy = deprecatedBy
+        elif self.obsoletedBy is not None:
+            self.deprecationType = 'obsoletion'
+            supercededBy = obsoletedBy
+
+        if supercededBy is not None:
+            if supercededBy == '' and not self.deprecationType == 'promotion':
+                pass # supercedingAPIVersion, supercedingExtension is None
+            elif supercededBy.startswith(self.conventions.api_version_prefix):
+                self.supercedingAPIVersion = supercededBy
+            elif supercededBy.startswith(self.conventions.api_prefix):
+                self.supercedingExtension = supercededBy
+            else:
+                self.generator.logMsg('error', 'Unrecognized ' + self.deprecationType + ' attribute value \'' + supercededBy + '\'!')
+
+        match = EXT_NAME_DECOMPOSE_RE.match(self.name)
+        self.vendor = match.group('tag')
+        self.bare_name = match.group('name')
+
+    def __str__(self):
+        return self.name
+    def __eq__(self, other):
+        return self.name == other.name
+    def __ne__(self, other):
+        return self.name != other.name
+
+    def __lt__(self, other):
+        self_is_KHR = self.name.startswith(self.conventions.KHR_prefix)
+        self_is_EXT = self.name.startswith(self.conventions.EXT_prefix)
+        other_is_KHR = other.name.startswith(self.conventions.KHR_prefix)
+        other_is_EXT = other.name.startswith(self.conventions.EXT_prefix)
+
+        swap = False
+        if self_is_KHR and not other_is_KHR:
+            return not swap
+        if other_is_KHR and not self_is_KHR:
+            return swap
+        if self_is_EXT and not other_is_EXT:
+            return not swap
+        if other_is_EXT and not self_is_EXT:
+            return swap
+
+        return self.name < other.name
+
+    def typeToStr(self):
+        if self.ext_type == 'instance':
+            return 'Instance extension'
+        if self.ext_type == 'device':
+            return 'Device extension'
+
+        if self.ext_type is not None:
+            self.generator.logMsg('warn', 'The type attribute of ' + self.name + ' extension is neither \'instance\' nor \'device\'. That is invalid (at the time this script was written).')
+        else: # should be unreachable
+            self.generator.logMsg('error', 'Logic error in typeToStr(): Missing type attribute!')
+        return None
+
+    def specLink(self, xrefName, xrefText, isRefpage = False):
+        """Generate a string containing a link to a specification anchor in
+           asciidoctor markup form.
+
+        - xrefName - anchor name in the spec
+        - xrefText - text to show for the link, or None
+        - isRefpage = True if generating a refpage include, False if
+          generating a specification extension appendix include"""
+
+        if isRefpage:
+            # Always link into API spec
+            specURL = self.conventions.specURL('api')
+            return 'link:{}#{}[{}^]'.format(specURL, xrefName, xrefText)
+        else:
+            return '<<' + xrefName + ', ' + xrefText + '>>'
+
+    def conditionalLinkCoreAPI(self, apiVersion, linkSuffix, isRefpage):
+        versionMatch = re.match(self.conventions.api_version_prefix + r'(\d+)_(\d+)', apiVersion)
+        major = versionMatch.group(1)
+        minor = versionMatch.group(2)
+
+        dottedVersion = major + '.' + minor
+
+        xrefName = 'versions-' + dottedVersion + linkSuffix
+        xrefText = self.conventions.api_name() + ' ' + dottedVersion
+
+        doc  = 'ifdef::' + apiVersion + '[]\n'
+        doc += '    ' + self.specLink(xrefName, xrefText, isRefpage) + '\n'
+        doc += 'endif::' + apiVersion + '[]\n'
+        doc += 'ifndef::' + apiVersion + '[]\n'
+        doc += '    ' + self.conventions.api_name() + ' ' + dottedVersion + '\n'
+        doc += 'endif::' + apiVersion + '[]\n'
+
+        return doc
+
+    def conditionalLinkExt(self, extName, indent = '    '):
+        doc  = 'ifdef::' + extName + '[]\n'
+        doc +=  indent + self.conventions.formatExtension(extName) + '\n'
+        doc += 'endif::' + extName + '[]\n'
+        doc += 'ifndef::' + extName + '[]\n'
+        doc += indent + '`' + extName + '`\n'
+        doc += 'endif::' + extName + '[]\n'
+
+        return doc
+
+    def resolveDeprecationChain(self, extensionsList, succeededBy, isRefpage, file):
+        ext = next(x for x in extensionsList if x.name == succeededBy)
+
+        if ext.deprecationType:
+            if ext.deprecationType == 'promotion':
+                if ext.supercedingAPIVersion:
+                    write('  ** Which in turn was _promoted_ to\n' + ext.conditionalLinkCoreAPI(ext.supercedingAPIVersion, '-promotions', isRefpage), file=file)
+                else: # ext.supercedingExtension
+                    write('  ** Which in turn was _promoted_ to extension\n' + ext.conditionalLinkExt(ext.supercedingExtension), file=file)
+                    ext.resolveDeprecationChain(extensionsList, ext.supercedingExtension, file)
+            elif ext.deprecationType == 'deprecation':
+                if ext.supercedingAPIVersion:
+                    write('  ** Which in turn was _deprecated_ by\n' + ext.conditionalLinkCoreAPI(ext.supercedingAPIVersion, '-new-feature', isRefpage), file=file)
+                elif ext.supercedingExtension:
+                    write('  ** Which in turn was _deprecated_ by\n' + ext.conditionalLinkExt(ext.supercedingExtension) + '    extension', file=file)
+                    ext.resolveDeprecationChain(extensionsList, ext.supercedingExtension, file)
+                else:
+                    write('  ** Which in turn was _deprecated_ without replacement', file=file)
+            elif ext.deprecationType == 'obsoletion':
+                if ext.supercedingAPIVersion:
+                    write('  ** Which in turn was _obsoleted_ by\n' + ext.conditionalLinkCoreAPI(ext.supercedingAPIVersion, '-new-feature', isRefpage), file=file)
+                elif ext.supercedingExtension:
+                    write('  ** Which in turn was _obsoleted_ by\n' + ext.conditionalLinkExt(ext.supercedingExtension) + '    extension', file=file)
+                    ext.resolveDeprecationChain(extensionsList, ext.supercedingExtension, file)
+                else:
+                    write('  ** Which in turn was _obsoleted_ without replacement', file=file)
+            else: # should be unreachable
+                self.generator.logMsg('error', 'Logic error in resolveDeprecationChain(): deprecationType is neither \'promotion\', \'deprecation\' nor \'obsoletion\'!')
+
+
+    def writeTag(self, tag, value, isRefpage, fp):
+        """Write a tag and (if non-None) a tag value to a file.
+
+        - tag - string tag name
+        - value - tag value, or None
+        - isRefpage - controls style in which the tag is marked up
+        - fp - open file pointer to write to"""
+
+        if isRefpage:
+            # Use subsection headers for the tag name
+            tagPrefix = '== '
+            tagSuffix = ''
+        else:
+            # Use an bolded item list for the tag name
+            tagPrefix = '*'
+            tagSuffix = '*::'
+
+        write(tagPrefix + tag + tagSuffix, file=fp)
+        if value is not None:
+            write(value, file=fp)
+
+        if isRefpage:
+            write('', file=fp)
+
+    def makeMetafile(self, extensionsList, isRefpage = False):
+        """Generate a file containing extension metainformation in
+           asciidoctor markup form.
+
+        - extensionsList - list of extensions spec is being generated against
+        - isRefpage - True if generating a refpage include, False if
+          generating a specification extension appendix include"""
+
+        if isRefpage:
+            filename = self.filename.replace('meta/', 'meta/refpage.')
+        else:
+            filename = self.filename
+
+        fp = self.generator.newFile(filename)
+
+        if not isRefpage:
+            write('[[' + self.name + ']]', file=fp)
+            write('=== ' + self.name, file=fp)
+            write('', file=fp)
+
+            self.writeTag('Name String', '`' + self.name + '`', isRefpage, fp)
+            self.writeTag('Extension Type', self.typeToStr(), isRefpage, fp)
+
+        self.writeTag('Registered Extension Number', self.number, isRefpage, fp)
+        self.writeTag('Revision', self.revision, isRefpage, fp)
+
+        # Only API extension dependencies are coded in XML, others are explicit
+        self.writeTag('Extension and Version Dependencies', None, isRefpage, fp)
+
+        write('  * Requires ' + self.conventions.api_name() + ' ' + self.requiresCore, file=fp)
+        if self.requires:
+            for dep in self.requires.split(','):
+                write('  * Requires', self.conventions.formatExtension(dep),
+                      file=fp)
+        if self.provisional == 'true':
+            write('  * *This is a _provisional_ extension and must: be used with caution.', file=fp)
+            write('    See the ' +
+                  self.specLink(xrefName = 'boilerplate-provisional-header',
+                                xrefText = 'description',
+                                isRefpage = isRefpage) +
+                  ' of provisional header files for enablement and stability details.*', file=fp)
+        write('', file=fp)
+
+        if self.deprecationType:
+            self.writeTag('Deprecation state', None, isRefpage, fp)
+
+            if self.deprecationType == 'promotion':
+                if self.supercedingAPIVersion:
+                    write('  * _Promoted_ to\n' + self.conditionalLinkCoreAPI(self.supercedingAPIVersion, '-promotions', isRefpage), file=fp)
+                else: # ext.supercedingExtension
+                    write('  * _Promoted_ to\n' + self.conditionalLinkExt(self.supercedingExtension) + '    extension', file=fp)
+                    self.resolveDeprecationChain(extensionsList, self.supercedingExtension, isRefpage, fp)
+            elif self.deprecationType == 'deprecation':
+                if self.supercedingAPIVersion:
+                    write('  * _Deprecated_ by\n' + self.conditionalLinkCoreAPI(self.supercedingAPIVersion, '-new-features', isRefpage), file=fp)
+                elif self.supercedingExtension:
+                    write('  * _Deprecated_ by\n' + self.conditionalLinkExt(self.supercedingExtension) + '    extension' , file=fp)
+                    self.resolveDeprecationChain(extensionsList, self.supercedingExtension, isRefpage, fp)
+                else:
+                    write('  * _Deprecated_ without replacement' , file=fp)
+            elif self.deprecationType == 'obsoletion':
+                if self.supercedingAPIVersion:
+                    write('  * _Obsoleted_ by\n' + self.conditionalLinkCoreAPI(self.supercedingAPIVersion, '-new-features', isRefpage), file=fp)
+                elif self.supercedingExtension:
+                    write('  * _Obsoleted_ by\n' + self.conditionalLinkExt(self.supercedingExtension) + '    extension' , file=fp)
+                    self.resolveDeprecationChain(extensionsList, self.supercedingExtension, isRefpage, fp)
+                else:
+                    # TODO: Does not make sense to retroactively ban use of extensions from 1.0.
+                    #       Needs some tweaks to the semantics and this message, when such extension(s) occur.
+                    write('  * _Obsoleted_ without replacement' , file=fp)
+            else: # should be unreachable
+                self.generator.logMsg('error', 'Logic error in makeMetafile(): deprecationType is neither \'promotion\', \'deprecation\' nor \'obsoletion\'!')
+
+        if self.specialuse is not None:
+            specialuses = self.specialuse.split(',')
+            if len(specialuses) > 1:
+                header = 'Special Uses'
+            else:
+                header = 'Special Use'
+            self.writeTag(header, None, isRefpage, fp)
+
+            for use in specialuses:
+                # Each specialuse attribute value expands an asciidoctor
+                # attribute of the same name, instead of using the shorter,
+                # and harder to understand attribute
+                write('* {}'.format(
+                      self.specLink(
+                           xrefName = self.conventions.special_use_section_anchor,
+                           xrefText = '{' + use + '}',
+                           isRefpage = isRefpage)), file=fp)
+
+        if self.conventions.write_contacts and not isRefpage:
+            write('*Contact*::', file=fp)
+            contacts = self.contact.split(',')
+            for contact in contacts:
+                contactWords = contact.strip().split()
+                name = ' '.join(contactWords[:-1])
+                handle = contactWords[-1]
+                if handle.startswith('gitlab:'):
+                    prettyHandle = 'icon:gitlab[alt=GitLab, role="red"]' + handle.replace('gitlab:@', '')
+                elif handle.startswith('@'):
+                    trackerLink = 'link:++https://github.com/KhronosGroup/Vulkan-Docs/issues/new?title=' + self.name + ':%20&body=' + handle + '%20++'
+                    prettyHandle = trackerLink + '[icon:github[alt=GitHub, role="black"]' + handle[1:] + ']'
+                else:
+                    prettyHandle = handle
+
+                write('  * ' + name + ' ' + prettyHandle, file=fp)
+
+        fp.close()
+
+class ExtensionMetaDocOutputGenerator(OutputGenerator):
+    """ExtensionMetaDocOutputGenerator - subclass of OutputGenerator.
+
+    Generates AsciiDoc includes with metainformation for the API extension
+    appendices. The fields used from <extension> tags in the API XML are:
+
+    - name          extension name string
+    - number        extension number (optional)
+    - contact       name and github login or email address (optional)
+    - type          'instance' | 'device' (optional)
+    - requires      list of comma-separated required API extensions (optional)
+    - requiresCore  required core version of API (optional)
+    - promotedTo    extension or API version it was promoted to
+    - deprecatedBy  extension or API version which deprecated this extension,
+                    or empty string if deprecated without replacement
+    - obsoletedBy   extension or API version which obsoleted this extension,
+                    or empty string if obsoleted without replacement
+    - provisional   'true' if this extension is released provisionally"""
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.extensions = []
+        # List of strings containing all vendor tags
+        self.vendor_tags = []
+        self.file_suffix = ''
+
+    def newFile(self, filename):
+        self.logMsg('diag', '# Generating include file:', filename)
+        fp = open(filename, 'w', encoding='utf-8')
+        write(self.genOpts.conventions.warning_comment, file=fp)
+        return fp
+
+    def beginFile(self, genOpts):
+        OutputGenerator.beginFile(self, genOpts)
+
+        self.directory = self.genOpts.directory
+        self.file_suffix = self.genOpts.conventions.file_suffix
+
+        # Iterate over all 'tag' Elements and add the names of all the valid vendor
+        # tags to the list
+        root = self.registry.tree.getroot()
+        for tag in root.findall('tags/tag'):
+            self.vendor_tags.append(tag.get('name'))
+
+        # Create subdirectory, if needed
+        self.makeDir(self.directory)
+
+    def conditionalExt(self, extName, content, ifdef = None, condition = None):
+        doc = ''
+
+        innerdoc  = 'ifdef::' + extName + '[]\n'
+        innerdoc += content + '\n'
+        innerdoc += 'endif::' + extName + '[]\n'
+
+        if ifdef:
+            if ifdef == 'ifndef':
+                if condition:
+                    doc += 'ifndef::' + condition + '[]\n'
+                    doc += innerdoc
+                    doc += 'endif::' + condition + '[]\n'
+                else: # no condition is as if condition is defined; "nothing" is always defined :p
+                    pass # so no output
+            elif ifdef == 'ifdef':
+                if condition:
+                    doc += 'ifdef::' + condition + '+' + extName + '[]\n'
+                    doc += content + '\n' # does not include innerdoc; the ifdef was merged with the one above
+                    doc += 'endif::' + condition + '+' + extName + '[]\n'
+                else: # no condition is as if condition is defined; "nothing" is always defined :p
+                    doc += innerdoc
+            else: # should be unreachable
+                raise RuntimeError('Should be unreachable: ifdef is neither \'ifdef \' nor \'ifndef\'!')
+        else:
+            doc += innerdoc
+
+        return doc
+
+    def makeExtensionInclude(self, ext):
+        return self.conventions.extension_include_string(ext)
+
+    def endFile(self):
+        self.extensions.sort()
+
+        # Generate metadoc extension files, in refpage and non-refpage form
+        for ext in self.extensions:
+            ext.makeMetafile(self.extensions, isRefpage = False)
+            if self.conventions.write_refpage_include:
+                ext.makeMetafile(self.extensions, isRefpage = True)
+
+        # Generate list of promoted extensions
+        promotedExtensions = {}
+        for ext in self.extensions:
+            if ext.deprecationType == 'promotion' and ext.supercedingAPIVersion:
+                promotedExtensions.setdefault(ext.supercedingAPIVersion, []).append(ext)
+
+        for coreVersion, extensions in promotedExtensions.items():
+            promoted_extensions_fp = self.newFile(self.directory + '/promoted_extensions_' + coreVersion + self.file_suffix)
+
+            for ext in extensions:
+                indent = ''
+                write('  * {blank}\n+\n' + ext.conditionalLinkExt(ext.name, indent), file=promoted_extensions_fp)
+
+            promoted_extensions_fp.close()
+
+        # Re-sort to match earlier behavior
+        # TODO: Remove this extra sort when re-arranging section order OK.
+
+        def makeSortKey(ext):
+            name = ext.name.lower()
+            prefixes = self.conventions.extension_index_prefixes
+            for i, prefix in enumerate(prefixes):
+                if ext.name.startswith(prefix):
+                    return (i, name)
+            return (len(prefixes), name)
+
+        self.extensions.sort(key=makeSortKey)
+
+        # Generate include directives for the extensions appendix, grouping
+        # extensions by status (current, deprecated, provisional, etc.)
+        with self.newFile(self.directory + '/current_extensions_appendix' + self.file_suffix) as current_extensions_appendix_fp, \
+                self.newFile(self.directory + '/deprecated_extensions_appendix' + self.file_suffix) as deprecated_extensions_appendix_fp, \
+                self.newFile(self.directory + '/current_extension_appendices' + self.file_suffix) as current_extension_appendices_fp, \
+                self.newFile(self.directory + '/current_extension_appendices_toc' + self.file_suffix) as current_extension_appendices_toc_fp, \
+                self.newFile(self.directory + '/deprecated_extension_appendices' + self.file_suffix) as deprecated_extension_appendices_fp, \
+                self.newFile(self.directory + '/deprecated_extension_appendices_toc' + self.file_suffix) as deprecated_extension_appendices_toc_fp, \
+                self.newFile(self.directory + '/deprecated_extensions_guard_macro' + self.file_suffix) as deprecated_extensions_guard_macro_fp, \
+                self.newFile(self.directory + '/provisional_extensions_appendix' + self.file_suffix) as provisional_extensions_appendix_fp, \
+                self.newFile(self.directory + '/provisional_extension_appendices' + self.file_suffix) as provisional_extension_appendices_fp, \
+                self.newFile(self.directory + '/provisional_extension_appendices_toc' + self.file_suffix) as provisional_extension_appendices_toc_fp, \
+                self.newFile(self.directory + '/provisional_extensions_guard_macro' + self.file_suffix) as provisional_extensions_guard_macro_fp:
+
+            write('include::deprecated_extensions_guard_macro' + self.file_suffix + '[]', file=current_extensions_appendix_fp)
+            write('', file=current_extensions_appendix_fp)
+            write('ifndef::HAS_DEPRECATED_EXTENSIONS[]', file=current_extensions_appendix_fp)
+            write('[[extension-appendices-list]]', file=current_extensions_appendix_fp)
+            write('== List of Extensions', file=current_extensions_appendix_fp)
+            write('endif::HAS_DEPRECATED_EXTENSIONS[]', file=current_extensions_appendix_fp)
+            write('ifdef::HAS_DEPRECATED_EXTENSIONS[]', file=current_extensions_appendix_fp)
+            write('[[extension-appendices-list]]', file=current_extensions_appendix_fp)
+            write('== List of Current Extensions', file=current_extensions_appendix_fp)
+            write('endif::HAS_DEPRECATED_EXTENSIONS[]', file=current_extensions_appendix_fp)
+            write('', file=current_extensions_appendix_fp)
+            write('include::current_extension_appendices_toc' + self.file_suffix + '[]', file=current_extensions_appendix_fp)
+            write('<<<', file=current_extensions_appendix_fp)
+            write('include::current_extension_appendices' + self.file_suffix + '[]', file=current_extensions_appendix_fp)
+
+            write('include::deprecated_extensions_guard_macro' + self.file_suffix + '[]', file=deprecated_extensions_appendix_fp)
+            write('', file=deprecated_extensions_appendix_fp)
+            write('ifdef::HAS_DEPRECATED_EXTENSIONS[]', file=deprecated_extensions_appendix_fp)
+            write('[[deprecated-extension-appendices-list]]', file=deprecated_extensions_appendix_fp)
+            write('== List of Deprecated Extensions', file=deprecated_extensions_appendix_fp)
+            write('include::deprecated_extension_appendices_toc' + self.file_suffix + '[]', file=deprecated_extensions_appendix_fp)
+            write('<<<', file=deprecated_extensions_appendix_fp)
+            write('include::deprecated_extension_appendices' + self.file_suffix + '[]', file=deprecated_extensions_appendix_fp)
+            write('endif::HAS_DEPRECATED_EXTENSIONS[]', file=deprecated_extensions_appendix_fp)
+
+            # add include guard to allow multiple includes
+            write('ifndef::DEPRECATED_EXTENSIONS_GUARD_MACRO_INCLUDE_GUARD[]', file=deprecated_extensions_guard_macro_fp)
+            write(':DEPRECATED_EXTENSIONS_GUARD_MACRO_INCLUDE_GUARD:\n', file=deprecated_extensions_guard_macro_fp)
+            write('ifndef::PROVISIONAL_EXTENSIONS_GUARD_MACRO_INCLUDE_GUARD[]', file=provisional_extensions_guard_macro_fp)
+            write(':PROVISIONAL_EXTENSIONS_GUARD_MACRO_INCLUDE_GUARD:\n', file=provisional_extensions_guard_macro_fp)
+
+            write('include::provisional_extensions_guard_macro' + self.file_suffix + '[]', file=provisional_extensions_appendix_fp)
+            write('', file=provisional_extensions_appendix_fp)
+            write('ifdef::HAS_PROVISIONAL_EXTENSIONS[]', file=provisional_extensions_appendix_fp)
+            write('[[provisional-extension-appendices-list]]', file=provisional_extensions_appendix_fp)
+            write('== List of Provisional Extensions', file=provisional_extensions_appendix_fp)
+            write('include::provisional_extension_appendices_toc' + self.file_suffix + '[]', file=provisional_extensions_appendix_fp)
+            write('<<<', file=provisional_extensions_appendix_fp)
+            write('include::provisional_extension_appendices' + self.file_suffix + '[]', file=provisional_extensions_appendix_fp)
+            write('endif::HAS_PROVISIONAL_EXTENSIONS[]', file=provisional_extensions_appendix_fp)
+
+            for ext in self.extensions:
+                include = self.makeExtensionInclude(ext)
+                link = '  * ' + self.conventions.formatExtension(ext.name)
+                if ext.provisional == 'true':
+                    write(self.conditionalExt(ext.name, include), file=provisional_extension_appendices_fp)
+                    write(self.conditionalExt(ext.name, link), file=provisional_extension_appendices_toc_fp)
+                    write(self.conditionalExt(ext.name, ':HAS_PROVISIONAL_EXTENSIONS:'), file=provisional_extensions_guard_macro_fp)
+                elif ext.deprecationType is None:
+                    write(self.conditionalExt(ext.name, include), file=current_extension_appendices_fp)
+                    write(self.conditionalExt(ext.name, link), file=current_extension_appendices_toc_fp)
+                else:
+                    condition = ext.supercedingAPIVersion if ext.supercedingAPIVersion else ext.supercedingExtension  # potentially None too
+
+                    write(self.conditionalExt(ext.name, include, 'ifndef', condition), file=current_extension_appendices_fp)
+                    write(self.conditionalExt(ext.name, link, 'ifndef', condition), file=current_extension_appendices_toc_fp)
+
+                    write(self.conditionalExt(ext.name, include, 'ifdef', condition), file=deprecated_extension_appendices_fp)
+                    write(self.conditionalExt(ext.name, link, 'ifdef', condition), file=deprecated_extension_appendices_toc_fp)
+
+                    write(self.conditionalExt(ext.name, ':HAS_DEPRECATED_EXTENSIONS:', 'ifdef', condition), file=deprecated_extensions_guard_macro_fp)
+
+            write('endif::DEPRECATED_EXTENSIONS_GUARD_MACRO_INCLUDE_GUARD[]', file=deprecated_extensions_guard_macro_fp)
+
+        OutputGenerator.endFile(self)
+
+    def beginFeature(self, interface, emit):
+        # Start processing in superclass
+        OutputGenerator.beginFeature(self, interface, emit)
+
+        if interface.tag != 'extension':
+            self.logMsg('diag', 'beginFeature: ignoring non-extension feature', self.featureName)
+            return
+
+        # These attributes must exist
+        name = self.featureName
+        number = self.getAttrib(interface, 'number')
+        ext_type = self.getAttrib(interface, 'type')
+        revision = self.getSpecVersion(interface, name)
+
+        # These attributes are optional
+        OPTIONAL = False
+        requires = self.getAttrib(interface, 'requires', OPTIONAL)
+        requiresCore = self.getAttrib(interface, 'requiresCore', OPTIONAL, '1.0') # TODO update this line with update_version.py
+        contact = self.getAttrib(interface, 'contact', OPTIONAL)
+        promotedTo = self.getAttrib(interface, 'promotedto', OPTIONAL)
+        deprecatedBy = self.getAttrib(interface, 'deprecatedby', OPTIONAL)
+        obsoletedBy = self.getAttrib(interface, 'obsoletedby', OPTIONAL)
+        provisional = self.getAttrib(interface, 'provisional', OPTIONAL, 'false')
+        specialuse = self.getAttrib(interface, 'specialuse', OPTIONAL)
+
+        filename = self.directory + '/' + name + self.file_suffix
+
+        extdata = Extension(
+            generator = self,
+            filename = filename,
+            name = name,
+            number = number,
+            ext_type = ext_type,
+            requires = requires,
+            requiresCore = requiresCore,
+            contact = contact,
+            promotedTo = promotedTo,
+            deprecatedBy = deprecatedBy,
+            obsoletedBy = obsoletedBy,
+            provisional = provisional,
+            revision = revision,
+            specialuse = specialuse)
+        self.extensions.append(extdata)
+
+
+    def endFeature(self):
+        # Finish processing in superclass
+        OutputGenerator.endFeature(self)
+
+    def getAttrib(self, elem, attribute, required=True, default=None):
+        """Query an attribute from an element, or return a default value
+
+        - elem - element to query
+        - attribute - attribute name
+        - required - whether attribute must exist
+        - default - default value if attribute not present"""
+        attrib = elem.get(attribute, default)
+        if required and (attrib is None):
+            name = elem.get('name', 'UNKNOWN')
+            self.logMsg('error', 'While processing \'' + self.featureName + ', <' + elem.tag + '> \'' + name + '\' does not contain required attribute \'' + attribute + '\'')
+        return attrib
+
+    def numbersToWords(self, name):
+        allowlist = ['WIN32', 'INT16', 'D3D1']
+
+        # temporarily replace allowlist items
+        for i, w in enumerate(allowlist):
+            name = re.sub(w, '{' + str(i) + '}', name)
+
+        name = re.sub(r'(?<=[A-Z])(\d+)(?![A-Z])', r'_\g<1>', name)
+
+        # undo allowlist substitution
+        for i, w in enumerate(allowlist):
+            name = re.sub('\\{' + str(i) + '}', w, name)
+
+        return name
+
+    def getSpecVersion(self, elem, extname, default=None):
+        """Determine the extension revision from the EXTENSION_NAME_SPEC_VERSION
+        enumerant.
+
+        - elem - <extension> element to query
+        - extname - extension name from the <extension> 'name' attribute
+        - default - default value if SPEC_VERSION token not present"""
+        # The literal enumerant name to match
+        versioningEnumName = self.numbersToWords(extname.upper()) + '_SPEC_VERSION'
+
+        for enum in elem.findall('./require/enum'):
+            enumName = self.getAttrib(enum, 'name')
+            if enumName == versioningEnumName:
+                return self.getAttrib(enum, 'value')
+
+        #if not found:
+        for enum in elem.findall('./require/enum'):
+            enumName = self.getAttrib(enum, 'name')
+            if enumName.find('SPEC_VERSION') != -1:
+                self.logMsg('diag', 'Missing ' + versioningEnumName + '! Potential misnamed candidate ' + enumName + '.')
+                return self.getAttrib(enum, 'value')
+
+        self.logMsg('error', 'Missing ' + versioningEnumName + '!')
+        return default
--- Vulkan-Headers-1.2.156.orig/registry/hostsyncgenerator.py
+++ Vulkan-Headers-1.2.156/registry/hostsyncgenerator.py
@@ -0,0 +1,154 @@
+#!/usr/bin/python3 -i
+#
+# Copyright (c) 2013-2020 The Khronos Group Inc.
+#
+# SPDX-License-Identifier: Apache-2.0
+
+from generator import OutputGenerator, write
+from spec_tools.attributes import ExternSyncEntry
+from spec_tools.validity import ValidityCollection, ValidityEntry
+from spec_tools.util import getElemName
+
+
+class HostSynchronizationOutputGenerator(OutputGenerator):
+    """HostSynchronizationOutputGenerator - subclass of OutputGenerator.
+    Generates AsciiDoc includes of the externsync parameter table for the
+    fundamentals chapter of the API specification. Similar to
+    DocOutputGenerator.
+
+    ---- methods ----
+    HostSynchronizationOutputGenerator(errFile, warnFile, diagFile) - args as for
+      OutputGenerator. Defines additional internal state.
+    ---- methods overriding base class ----
+    genCmd(cmdinfo)"""
+    # Generate Host Synchronized Parameters in a table at the top of the spec
+
+    threadsafety = {
+        'parameters': ValidityCollection(),
+        'parameterlists': ValidityCollection(),
+        'implicit': ValidityCollection()
+    }
+
+    def makeParameterName(self, name):
+        return 'pname:' + name
+
+    def makeFLink(self, name):
+        return 'flink:' + name
+
+    def writeBlock(self, basename, title, contents):
+        """Generate an include file.
+
+        - directory - subdirectory to put file in
+        - basename - base name of the file
+        - contents - contents of the file (Asciidoc boilerplate aside)"""
+        filename = self.genOpts.directory + '/' + basename
+        self.logMsg('diag', '# Generating include file:', filename)
+        with open(filename, 'w', encoding='utf-8') as fp:
+            write(self.genOpts.conventions.warning_comment, file=fp)
+
+            if contents:
+                write('.%s' % title, file=fp)
+                write('****', file=fp)
+                write(contents, file=fp, end='')
+                write('****', file=fp)
+                write('', file=fp)
+            else:
+                self.logMsg('diag', '# No contents for:', filename)
+
+    def writeInclude(self):
+        "Generates the asciidoc include files."""
+        self.writeBlock('parameters.txt',
+                        'Externally Synchronized Parameters',
+                        self.threadsafety['parameters'])
+        self.writeBlock('parameterlists.txt',
+                        'Externally Synchronized Parameter Lists',
+                        self.threadsafety['parameterlists'])
+        self.writeBlock('implicit.txt',
+                        'Implicit Externally Synchronized Parameters',
+                        self.threadsafety['implicit'])
+
+    def paramIsArray(self, param):
+        """Check if the parameter passed in is a pointer to an array."""
+        return param.get('len') is not None
+
+    def paramIsPointer(self, param):
+        """Check if the parameter passed in is a pointer."""
+        tail = param.find('type').tail
+        return tail is not None and '*' in tail
+
+    def makeThreadSafetyBlocks(self, cmd, paramtext):
+        # See also makeThreadSafetyBlock in validitygenerator.py - similar but not entirely identical
+        protoname = cmd.find('proto/name').text
+
+        # Find and add any parameters that are thread unsafe
+        explicitexternsyncparams = cmd.findall(paramtext + "[@externsync]")
+        if explicitexternsyncparams is not None:
+            for param in explicitexternsyncparams:
+                self.makeThreadSafetyForParam(protoname, param)
+
+        # Find and add any "implicit" parameters that are thread unsafe
+        implicitexternsyncparams = cmd.find('implicitexternsyncparams')
+        if implicitexternsyncparams is not None:
+            for elem in implicitexternsyncparams:
+                entry = ValidityEntry()
+                entry += elem.text
+                entry += ' in '
+                entry += self.makeFLink(protoname)
+                self.threadsafety['implicit'] += entry
+
+        # Add a VU for any command requiring host synchronization.
+        # This could be further parameterized, if a future non-Vulkan API
+        # requires it.
+        if self.genOpts.conventions.is_externsync_command(protoname):
+            entry = ValidityEntry()
+            entry += 'The sname:VkCommandPool that pname:commandBuffer was allocated from, in '
+            entry += self.makeFLink(protoname)
+            self.threadsafety['implicit'] += entry
+
+    def makeThreadSafetyForParam(self, protoname, param):
+        """Create thread safety validity for a single param of a command."""
+        externsyncattribs = ExternSyncEntry.parse_externsync_from_param(param)
+        param_name = getElemName(param)
+
+        for attrib in externsyncattribs:
+            entry = ValidityEntry()
+            is_array = False
+            if attrib.entirely_extern_sync:
+                # "true" or "true_with_children"
+                if self.paramIsArray(param):
+                    entry += 'Each element of the '
+                    is_array = True
+                elif self.paramIsPointer(param):
+                    entry += 'The object referenced by the '
+                else:
+                    entry += 'The '
+
+                entry += self.makeParameterName(param_name)
+                entry += ' parameter'
+
+                if attrib.children_extern_sync:
+                    entry += ', and any child handles,'
+
+            else:
+                # parameter/member reference
+                readable = attrib.get_human_readable(make_param_name=self.makeParameterName)
+                is_array = (' element of ' in readable)
+                entry += readable
+
+            entry += ' in '
+            entry += self.makeFLink(protoname)
+
+            if is_array:
+                self.threadsafety['parameterlists'] += entry
+            else:
+                self.threadsafety['parameters'] += entry
+
+    def genCmd(self, cmdinfo, name, alias):
+        "Generate command."
+        OutputGenerator.genCmd(self, cmdinfo, name, alias)
+
+        # @@@ (Jon) something needs to be done here to handle aliases, probably
+
+        self.makeThreadSafetyBlocks(cmdinfo.elem, 'param')
+
+        self.writeInclude()
--- Vulkan-Headers-1.2.156.orig/registry/interfacedocgenerator.py
+++ Vulkan-Headers-1.2.156/registry/interfacedocgenerator.py
@@ -0,0 +1,118 @@
+#!/usr/bin/python3 -i
+#
+# Copyright (c) 2013-2020 The Khronos Group Inc.
+#
+# SPDX-License-Identifier: Apache-2.0
+
+import re
+from generator import OutputGenerator, write
+
+def interfaceDocSortKey(item):
+    if item == None:
+        return '\0'
+    else:
+        return item.casefold()
+
+class InterfaceDocGenerator(OutputGenerator):
+    """InterfaceDocGenerator - subclass of OutputGenerator.
+    Generates AsciiDoc includes of the interfaces added by a an API version
+    or extension."""
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+        self.features = []
+
+    def beginFile(self, genOpts):
+        OutputGenerator.beginFile(self, genOpts)
+
+        # Create subdirectory, if needed
+        self.makeDir(self.genOpts.directory)
+
+    def beginFeature(self, interface, emit):
+        # Start processing in superclass
+        OutputGenerator.beginFeature(self, interface, emit)
+
+        self.features.append( self.featureName )
+
+    def endFeature(self):
+        # Finish processing in superclass
+        OutputGenerator.endFeature(self)
+
+    def writeNewInterfaces(self, feature, key, title, markup, fp):
+        dict = self.featureDictionary[feature][key]
+
+        parentmarkup = markup
+        if key == 'enumconstant':
+            parentmarkup = 'elink:'
+
+        if dict:
+            write('=== ' + title, file=fp)
+            write('',file=fp)
+
+            # Loop through required blocks, sorted so they start with "core" features
+            for required in sorted(dict, key = interfaceDocSortKey):
+                if required is not None:
+                    requiredlink = 'apiext:' + required
+                    match = re.search("[A-Z]+_VERSION_([0-9]+)_([0-9]+)",required)
+                    if match is not None:
+                        major = match.group(1)
+                        minor = match.group(2)
+                        version = major + '.' + minor
+                        requiredlink = '<<versions-' + version + ', Version ' + version + '>>'
+
+                    write('ifdef::' + required + '[]', file=fp)
+                    write('If ' + requiredlink + ' is supported:', file=fp)
+                    write('',file=fp)
+
+                # Commands are relatively straightforward
+                if key == 'command':
+                    for api in sorted(dict[required]):
+                        write('  * ' + markup + api, file=fp)
+                # Types and constants are potentially parented, so need to handle that
+                else:
+                    # Loop through parents, sorted so they start with unparented items
+                    for parent in sorted(dict[required], key = interfaceDocSortKey):
+                        parentstring = ''
+                        if parent:
+                            parentstring = parentmarkup + (', ' + markup).join(parent.split(','))
+                            write('  * Extending ' + parentstring + ':', file=fp)
+                            for api in sorted(dict[required][parent]):
+                                write('  ** ' + markup + api, file=fp)
+                        else:
+                            for api in sorted(dict[required][parent]):
+                                write('  * ' + markup + api, file=fp)
+
+                if required is not None:
+                    write('endif::' + required + '[]', file=fp)
+                write('',file=fp)
+
+    def makeInterfaceFile(self, feature):
+        """Generate a file containing feature interface documentation in
+           asciidoctor markup form.
+
+        - feature - name of the feature being generated"""
+
+        filename = feature + self.genOpts.conventions.file_suffix
+        fp = open(self.genOpts.directory + '/' + filename, 'w', encoding='utf-8')
+
+        # Write out the lists of new interfaces added by the feature
+        self.writeNewInterfaces(feature, 'define',      'New Macros',           'slink:',   fp)
+        self.writeNewInterfaces(feature, 'basetype',    'New Base Types',       'basetype:',fp)
+        self.writeNewInterfaces(feature, 'handle',      'New Object Types',     'slink:',   fp)
+        self.writeNewInterfaces(feature, 'command',     'New Commands',         'flink:',   fp)
+        self.writeNewInterfaces(feature, 'struct',      'New Structures',       'slink:',   fp)
+        self.writeNewInterfaces(feature, 'union',       'New Unions',           'slink:',   fp)
+        self.writeNewInterfaces(feature, 'funcpointer', 'New Function Pointers','tlink:',   fp)
+        self.writeNewInterfaces(feature, 'enum',        'New Enums',            'elink:',   fp)
+        self.writeNewInterfaces(feature, 'bitmask',     'New Bitmasks',         'tlink:',   fp)
+        self.writeNewInterfaces(feature, 'include',     'New Headers',          'code:',    fp)
+        self.writeNewInterfaces(feature, 'enumconstant','New Enum Constants',   'ename:',   fp)
+
+        fp.close()
+
+    def endFile(self):
+        # Generate metadoc feature files, in refpage and non-refpage form
+        for feature in self.features:
+            self.makeInterfaceFile(feature)
+
+        OutputGenerator.endFile(self)
--- Vulkan-Headers-1.2.156.orig/registry/pygenerator.py
+++ Vulkan-Headers-1.2.156/registry/pygenerator.py
@@ -0,0 +1,365 @@
+#!/usr/bin/python3 -i
+#
+# Copyright (c) 2013-2020 The Khronos Group Inc.
+#
+# SPDX-License-Identifier: Apache-2.0
+
+import sys
+from generator import OutputGenerator, enquote, noneStr, write
+import pprint
+
+class PyOutputGenerator(OutputGenerator):
+    """PyOutputGenerator - subclass of OutputGenerator.
+    Generates Python data structures describing API names and relationships.
+    Similar to DocOutputGenerator, but writes a single file."""
+
+    def apiName(self, name):
+        """Return True if name is in the reserved API namespace.
+
+        Delegates to the conventions object. """
+        return self.genOpts.conventions.is_api_name(name)
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+        # Track features being generated
+        self.features = []
+
+        # Reverse map from interface names to features requiring them
+        self.apimap = {}
+
+    def beginFile(self, genOpts):
+        OutputGenerator.beginFile(self, genOpts)
+        #
+        # Dictionaries are keyed by the name of the entity (e.g.
+        # self.structs is keyed by structure names). Values are
+        # the names of related entities (e.g. structs contain
+        # a list of type names of members, enums contain a list
+        # of enumerants belong to the enumerated type, etc.), or
+        # just None if there are no directly related entities.
+        #
+        # Collect the mappings, then emit the Python script in endFile
+        self.basetypes = {}
+        self.consts = {}
+        self.enums = {}
+        self.flags = {}
+        self.funcpointers = {}
+        self.protos = {}
+        self.structs = {}
+        self.handles = {}
+        self.defines = {}
+        self.alias = {}
+        # Dictionary containing the type of a type name
+        # (e.g. the string name of the dictionary with its contents).
+        self.typeCategory = {}
+        self.mapDict = {}
+
+    def addInterfaceMapping(self, api, feature, required):
+        """Add a reverse mapping in self.apimap from an API to a feature
+           requiring that API.
+
+        - api - name of the API
+        - feature - name of the feature requiring it
+        - required - None, or an additional feature dependency within
+          'feature' """
+
+        # Each entry in self.apimap contains one or more
+        # ( feature, required ) tuples.
+        deps = ( feature, required )
+
+        if api in self.apimap:
+            self.apimap[api].append(deps)
+        else:
+            self.apimap[api] = [ deps ]
+
+    def mapInterfaceKeys(self, feature, key):
+        """Construct reverse mapping of APIs to features requiring them in
+           self.apimap.
+
+        - feature - name of the feature being generated
+        - key - API category - 'define', 'basetype', etc."""
+
+        dict = self.featureDictionary[feature][key]
+
+        if dict:
+            # Not clear why handling of command vs. type APIs is different -
+            # see interfacedocgenerator.py, which this was based on.
+            if key == 'command':
+                for required in dict:
+                    for api in dict[required]:
+                        self.addInterfaceMapping(api, feature, required)
+            else:
+                for required in dict:
+                    for parent in dict[required]:
+                        for api in dict[required][parent]:
+                            self.addInterfaceMapping(api, feature, required)
+
+    def mapInterfaces(self, feature):
+        """Construct reverse mapping of APIs to features requiring them in
+           self.apimap.
+
+        - feature - name of the feature being generated"""
+
+        # Map each category of interface
+        self.mapInterfaceKeys(feature, 'basetype')
+        self.mapInterfaceKeys(feature, 'bitmask')
+        self.mapInterfaceKeys(feature, 'command')
+        self.mapInterfaceKeys(feature, 'define')
+        self.mapInterfaceKeys(feature, 'enum')
+        self.mapInterfaceKeys(feature, 'enumconstant')
+        self.mapInterfaceKeys(feature, 'funcpointer')
+        self.mapInterfaceKeys(feature, 'handle')
+        self.mapInterfaceKeys(feature, 'include')
+        self.mapInterfaceKeys(feature, 'struct')
+        self.mapInterfaceKeys(feature, 'union')
+
+    def endFile(self):
+        # Print out all the dictionaries as Python strings.
+        # Could just print(dict) but that's not human-readable
+        dicts = ( [ self.basetypes,     'basetypes' ],
+                  [ self.consts,        'consts' ],
+                  [ self.enums,         'enums' ],
+                  [ self.flags,         'flags' ],
+                  [ self.funcpointers,  'funcpointers' ],
+                  [ self.protos,        'protos' ],
+                  [ self.structs,       'structs' ],
+                  [ self.handles,       'handles' ],
+                  [ self.defines,       'defines' ],
+                  [ self.typeCategory,  'typeCategory' ],
+                  [ self.alias,         'alias' ] )
+        for (entry_dict, name) in dicts:
+            write(name + ' = {}', file=self.outFile)
+            for key in sorted(entry_dict.keys()):
+                write(name + '[' + enquote(key) + '] = ', entry_dict[key],
+                      file=self.outFile)
+
+        # Dictionary containing the relationships of a type
+        # (e.g. a dictionary with each related type as keys).
+        write('mapDict = {}', file=self.outFile)
+
+        # Could just print(self.mapDict), but prefer something
+        # human-readable and stable-ordered
+        for baseType in sorted(self.mapDict.keys()):
+            write('mapDict[' + enquote(baseType) + '] = ', file=self.outFile, end='')
+            pprint.pprint(self.mapDict[baseType], self.outFile)
+
+        # Generate feature <-> interface mappings
+        for feature in self.features:
+            self.mapInterfaces(feature)
+
+        # Write out the reverse map from APIs to requiring features
+        write('requiredBy = {}', file=self.outFile)
+
+        for api in sorted(self.apimap):
+            # Construct list of requirements as Python list arguments
+            ##reqs = ', '.join('({}, {})'.format(enquote(dep[0]), enquote(dep[1])) for dep in self.apimap[api])
+            ##write('requiredBy[{}] = ( {} )'.format(enquote(api), reqs), file=self.outFile)
+
+            # Ideally these would be sorted by dep[0] as well
+            reqs = ', '.join('({}, {})'.format(enquote(dep[0]), enquote(dep[1])) for dep in self.apimap[api])
+            write('requiredBy[{}] = {}'.format(enquote(api), pprint.saferepr(self.apimap[api])), file=self.outFile)
+
+        OutputGenerator.endFile(self)
+
+    def beginFeature(self, interface, emit):
+        # Start processing in superclass
+        OutputGenerator.beginFeature(self, interface, emit)
+
+        # Add this feature to the list being tracked
+        self.features.append( self.featureName )
+
+    def endFeature(self):
+        # Finish processing in superclass
+        OutputGenerator.endFeature(self)
+
+    def addName(self, entry_dict, name, value):
+        """Add a string entry to the dictionary, quoting it so it gets printed
+        out correctly in self.endFile()."""
+        entry_dict[name] = enquote(value)
+
+    def addMapping(self, baseType, refType):
+        """Add a mapping between types to mapDict.
+
+        Only include API types, so we don't end up with a lot of useless uint32_t and void types."""
+        if not self.apiName(baseType) or not self.apiName(refType):
+            self.logMsg('diag', 'PyOutputGenerator::addMapping: IGNORE map from', baseType, '<->', refType)
+            return
+
+        self.logMsg('diag', 'PyOutputGenerator::addMapping: map from',
+                    baseType, '<->', refType)
+
+        if baseType not in self.mapDict:
+            baseDict = {}
+            self.mapDict[baseType] = baseDict
+        else:
+            baseDict = self.mapDict[baseType]
+        if refType not in self.mapDict:
+            refDict = {}
+            self.mapDict[refType] = refDict
+        else:
+            refDict = self.mapDict[refType]
+
+        baseDict[refType] = None
+        refDict[baseType] = None
+
+    def genType(self, typeinfo, name, alias):
+        """Generate type.
+
+        - For 'struct' or 'union' types, defer to genStruct() to
+          add to the dictionary.
+        - For 'bitmask' types, add the type name to the 'flags' dictionary,
+          with the value being the corresponding 'enums' name defining
+          the acceptable flag bits.
+        - For 'enum' types, add the type name to the 'enums' dictionary,
+          with the value being '@STOPHERE@' (because this case seems
+          never to happen).
+        - For 'funcpointer' types, add the type name to the 'funcpointers'
+          dictionary.
+        - For 'handle' and 'define' types, add the handle or #define name
+          to the 'struct' dictionary, because that's how the spec sources
+          tag these types even though they aren't structs."""
+        OutputGenerator.genType(self, typeinfo, name, alias)
+        typeElem = typeinfo.elem
+        # If the type is a struct type, traverse the embedded <member> tags
+        # generating a structure. Otherwise, emit the tag text.
+        category = typeElem.get('category')
+
+        # Add a typeCategory{} entry for the category of this type.
+        self.addName(self.typeCategory, name, category)
+
+        if category in ('struct', 'union'):
+            self.genStruct(typeinfo, name, alias)
+        else:
+            if alias:
+                # Add name -> alias mapping
+                self.addName(self.alias, name, alias)
+
+                # Always emit an alias (?!)
+                count = 1
+
+                # May want to only emit full type definition when not an alias?
+            else:
+                # Extract the type name
+                # (from self.genOpts). Copy other text through unchanged.
+                # If the resulting text is an empty string, don't emit it.
+                count = len(noneStr(typeElem.text))
+                for elem in typeElem:
+                    count += len(noneStr(elem.text)) + len(noneStr(elem.tail))
+
+            if count > 0:
+                if category == 'bitmask':
+                    requiredEnum = typeElem.get('requires')
+                    self.addName(self.flags, name, requiredEnum)
+
+                    # This happens when the Flags type is defined, but no
+                    # FlagBits are defined yet.
+                    if requiredEnum is not None:
+                        self.addMapping(name, requiredEnum)
+                elif category == 'enum':
+                    # This case does not seem to come up. It nominally would
+                    # result from
+                    #   <type name="Something" category="enum"/>,
+                    # but the output generator doesn't emit them directly.
+                    self.logMsg('warn', 'PyOutputGenerator::genType: invalid \'enum\' category for name:', name)
+                elif category == 'funcpointer':
+                    self.funcpointers[name] = None
+                elif category == 'handle':
+                    self.handles[name] = None
+                elif category == 'define':
+                    self.defines[name] = None
+                elif category == 'basetype':
+                    # Don't add an entry for base types that are not API types
+                    # e.g. an API Bool type gets an entry, uint32_t does not
+                    if self.apiName(name):
+                        self.basetypes[name] = None
+                        self.addName(self.typeCategory, name, 'basetype')
+                    else:
+                        self.logMsg('diag', 'PyOutputGenerator::genType: unprocessed type:', name, 'category:', category)
+            else:
+                self.logMsg('diag', 'PyOutputGenerator::genType: unprocessed type:', name)
+
+    def genStruct(self, typeinfo, typeName, alias):
+        """Generate struct (e.g. C "struct" type).
+
+        Add the struct name to the 'structs' dictionary, with the
+        value being an ordered list of the struct member names."""
+        OutputGenerator.genStruct(self, typeinfo, typeName, alias)
+
+        if alias:
+            # Add name -> alias mapping
+            self.addName(self.alias, typeName, alias)
+        else:
+            # May want to only emit definition on this branch
+            True
+
+        members = [member.text for member in typeinfo.elem.findall('.//member/name')]
+        self.structs[typeName] = members
+        memberTypes = [member.text for member in typeinfo.elem.findall('.//member/type')]
+        for member_type in memberTypes:
+            self.addMapping(typeName, member_type)
+
+    def genGroup(self, groupinfo, groupName, alias):
+        """Generate group (e.g. C "enum" type).
+
+        These are concatenated together with other types.
+
+        - Add the enum type name to the 'enums' dictionary, with
+          the value being an ordered list of the enumerant names.
+        - Add each enumerant name to the 'consts' dictionary, with
+          the value being the enum type the enumerant is part of."""
+        OutputGenerator.genGroup(self, groupinfo, groupName, alias)
+        groupElem = groupinfo.elem
+
+        if alias:
+            # Add name -> alias mapping
+            self.addName(self.alias, groupName, alias)
+        else:
+            # May want to only emit definition on this branch
+            True
+
+        # Loop over the nested 'enum' tags.
+        enumerants = [elem.get('name') for elem in groupElem.findall('enum')]
+        for name in enumerants:
+            self.addName(self.consts, name, groupName)
+        self.enums[groupName] = enumerants
+
+    def genEnum(self, enuminfo, name, alias):
+        """Generate enumerant (compile-time constants).
+
+        - Add the constant name to the 'consts' dictionary, with the
+          value being None to indicate that the constant isn't
+          an enumeration value."""
+        OutputGenerator.genEnum(self, enuminfo, name, alias)
+
+        if name not in self.consts:
+            # Add a typeCategory{} entry for the category of this type.
+            self.addName(self.typeCategory, name, 'consts')
+            self.consts[name] = None
+        # Otherwise, don't add it to the consts dictionary because it's
+        # already present. This happens due to the generator 'reparentEnums'
+        # parameter being False, so each extension enum appears in both the
+        # <enums> type and in the <extension> or <feature> it originally
+        # came from.
+
+    def genCmd(self, cmdinfo, name, alias):
+        """Generate command.
+
+        - Add the command name to the 'protos' dictionary, with the
+          value being an ordered list of the parameter names."""
+        OutputGenerator.genCmd(self, cmdinfo, name, alias)
+
+        if alias:
+            # Add name -> alias mapping
+            self.addName(self.alias, name, alias)
+        else:
+            # May want to only emit definition on this branch
+            True
+
+        # Add a typeCategory{} entry for the category of this type.
+        self.addName(self.typeCategory, name, 'protos')
+
+        params = [param.text for param in cmdinfo.elem.findall('param/name')]
+        self.protos[name] = params
+        paramTypes = [param.text for param in cmdinfo.elem.findall('param/type')]
+        for param_type in paramTypes:
+            self.addMapping(name, param_type)
--- Vulkan-Headers-1.2.156.orig/registry/reflib.py
+++ Vulkan-Headers-1.2.156/registry/reflib.py
@@ -0,0 +1,663 @@
+#!/usr/bin/python3
+#
+# Copyright (c) 2016-2020 The Khronos Group Inc.
+#
+# SPDX-License-Identifier: Apache-2.0
+
+# Utility functions for automatic ref page generation and other script stuff
+
+import io
+import re
+import sys
+import subprocess
+
+# global errFile, warnFile, diagFile
+
+errFile = sys.stderr
+warnFile = sys.stdout
+diagFile = None
+logSourcefile = None
+logProcname = None
+logLine = None
+
+def unescapeQuotes(s):
+    """Remove \' escape sequences in a string (refpage description)"""
+    return s.replace('\\\'', '\'')
+
+def write(*args, **kwargs ):
+    file = kwargs.pop('file',sys.stdout)
+    end = kwargs.pop('end','\n')
+    file.write(' '.join(str(arg) for arg in args))
+    file.write(end)
+
+def setLogSourcefile(filename):
+    """Metadata which may be printed (if not None) for diagnostic messages"""
+    global logSourcefile
+    logSourcefile = filename
+
+def setLogProcname(procname):
+    global logProcname
+    logProcname = procname
+
+def setLogLine(line):
+    global logLine
+    logLine = line
+
+def logHeader(severity):
+    """Generate prefix for a diagnostic line using metadata and severity"""
+    global logSourcefile, logProcname, logLine
+
+    msg = severity + ': '
+    if logProcname:
+        msg = msg + ' in ' + logProcname
+    if logSourcefile:
+        msg = msg + ' for ' + logSourcefile
+    if logLine:
+        msg = msg + ' line ' + str(logLine)
+    return msg + ' '
+
+def setLogFile(setDiag, setWarn, filename):
+    """Set the file handle to log either or both warnings and diagnostics to.
+
+    - setDiag and setWarn are True if the corresponding handle is to be set.
+    - filename is None for no logging, '-' for stdout, or a pathname."""
+    global diagFile, warnFile
+
+    if filename is None:
+        return
+
+    if filename == '-':
+        fp = sys.stdout
+    else:
+        fp = open(filename, 'w', encoding='utf-8')
+
+    if setDiag:
+        diagFile = fp
+    if setWarn:
+        warnFile = fp
+
+def logDiag(*args, **kwargs):
+    file = kwargs.pop('file', diagFile)
+    end = kwargs.pop('end','\n')
+    if file is not None:
+        file.write(logHeader('DIAG') + ' '.join(str(arg) for arg in args))
+        file.write(end)
+
+def logWarn(*args, **kwargs):
+    file = kwargs.pop('file', warnFile)
+    end = kwargs.pop('end','\n')
+    if file is not None:
+        file.write(logHeader('WARN') + ' '.join(str(arg) for arg in args))
+        file.write(end)
+
+def logErr(*args, **kwargs):
+    file = kwargs.pop('file', errFile)
+    end = kwargs.pop('end','\n')
+
+    strfile = io.StringIO()
+    strfile.write(logHeader('ERROR') + ' '.join(str(arg) for arg in args))
+    strfile.write(end)
+
+    if file is not None:
+        file.write(strfile.getvalue())
+    sys.exit(1)
+
+def isempty(s):
+    """Return True if s is nothing but white space, False otherwise"""
+    return len(''.join(s.split())) == 0
+
+class pageInfo:
+    """Information about a ref page relative to the file it's extracted from."""
+    def __init__(self):
+        self.extractPage = True
+        """True if page should be extracted"""
+
+        self.Warning  = None
+        """string warning if page is suboptimal or can't be generated"""
+
+        self.embed    = False
+        """False or the name of the ref page this include is embedded within"""
+
+        self.type     = None
+        """'structs', 'protos', 'funcpointers', 'flags', 'enums'"""
+
+        self.name     = None
+        """struct/proto/enumerant/etc. name"""
+
+        self.desc     = None
+        """short description of ref page"""
+
+        self.begin    = None
+        """index of first line of the page (heuristic or // refBegin)"""
+
+        self.include  = None
+        """index of include:: line defining the page"""
+
+        self.param    = None
+        """index of first line of parameter/member definitions"""
+
+        self.body     = None
+        """index of first line of body text"""
+
+        self.validity = None
+        """index of validity include"""
+
+        self.end      = None
+        """index of last line of the page (heuristic validity include, or // refEnd)"""
+
+        self.alias    = ''
+        """aliases of this name, if supplied, or ''"""
+
+        self.refs     = ''
+        """cross-references on // refEnd line, if supplied"""
+
+        self.spec     = None
+        """'spec' attribute in refpage open block, if supplied, or None for the default ('api') type"""
+
+        self.anchor   = None
+        """'anchor' attribute in refpage open block, if supplied, or inferred to be the same as the 'name'"""
+
+def printPageInfoField(desc, line, file):
+    """Print a single field of a pageInfo struct, possibly None.
+
+    - desc - string description of field
+    - line - field value or None
+    - file - indexed by line"""
+    if line is not None:
+        logDiag(desc + ':', line + 1, '\t-> ', file[line], end='')
+    else:
+        logDiag(desc + ':', line)
+
+def printPageInfo(pi, file):
+    """Print out fields of a pageInfo struct
+
+    - pi - pageInfo
+    - file - indexed by pageInfo"""
+    logDiag('TYPE:   ', pi.type)
+    logDiag('NAME:   ', pi.name)
+    logDiag('WARNING:', pi.Warning)
+    logDiag('EXTRACT:', pi.extractPage)
+    logDiag('EMBED:  ', pi.embed)
+    logDiag('DESC:   ', pi.desc)
+    printPageInfoField('BEGIN   ', pi.begin,    file)
+    printPageInfoField('INCLUDE ', pi.include,  file)
+    printPageInfoField('PARAM   ', pi.param,    file)
+    printPageInfoField('BODY    ', pi.body,     file)
+    printPageInfoField('VALIDITY', pi.validity, file)
+    printPageInfoField('END     ', pi.end,      file)
+    logDiag('REFS: "' + pi.refs + '"')
+
+def prevPara(file, line):
+    """Go back one paragraph from the specified line and return the line number
+    of the first line of that paragraph.
+
+    Paragraphs are delimited by blank lines. It is assumed that the
+    current line is the first line of a paragraph.
+
+    - file is an array of strings
+    - line is the starting point (zero-based)"""
+    # Skip over current paragraph
+    while (line >= 0 and not isempty(file[line])):
+        line = line - 1
+    # Skip over white space
+    while (line >= 0 and isempty(file[line])):
+        line = line - 1
+    # Skip to first line of previous paragraph
+    while (line >= 1 and not isempty(file[line-1])):
+        line = line - 1
+    return line
+
+def nextPara(file, line):
+    """Go forward one paragraph from the specified line and return the line
+    number of the first line of that paragraph.
+
+    Paragraphs are delimited by blank lines. It is assumed that the
+    current line is standalone (which is bogus).
+
+    - file is an array of strings
+    - line is the starting point (zero-based)"""
+    maxLine = len(file) - 1
+    # Skip over current paragraph
+    while (line != maxLine and not isempty(file[line])):
+        line = line + 1
+    # Skip over white space
+    while (line != maxLine and isempty(file[line])):
+        line = line + 1
+    return line
+
+def lookupPage(pageMap, name):
+    """Return (creating if needed) the pageInfo entry in pageMap for name"""
+    if name not in pageMap:
+        pi = pageInfo()
+        pi.name = name
+        pageMap[name] = pi
+    else:
+        pi = pageMap[name]
+    return pi
+
+def loadFile(filename):
+    """Load a file into a list of strings. Return the list or None on failure"""
+    try:
+        fp = open(filename, 'r', encoding='utf-8')
+    except:
+        logWarn('Cannot open file', filename, ':', sys.exc_info()[0])
+        return None
+
+    file = fp.readlines()
+    fp.close()
+
+    return file
+
+def clampToBlock(line, minline, maxline):
+    """Clamp a line number to be in the range [minline,maxline].
+
+    If the line number is None, just return it.
+    If minline is None, don't clamp to that value."""
+    if line is None:
+        return line
+    if minline and line < minline:
+        return minline
+    if line > maxline:
+        return maxline
+
+    return line
+
+def fixupRefs(pageMap, specFile, file):
+    """Fill in missing fields in pageInfo structures, to the extent they can be
+    inferred.
+
+    - pageMap - dictionary of pageInfo structures
+    - specFile - filename
+    - file - list of strings making up the file, indexed by pageInfo"""
+    # All potential ref pages are now in pageMap. Process them to
+    # identify actual page start/end/description boundaries, if
+    # not already determined from the text.
+    for name in sorted(pageMap.keys()):
+        pi = pageMap[name]
+
+        # # If nothing is found but an include line with no begin, validity,
+        # # or end, this is not intended as a ref page (yet). Set the begin
+        # # line to the include line, so autogeneration can at least
+        # # pull the include out, but mark it not to be extracted.
+        # # Examples include the host sync table includes in
+        # # chapters/fundamentals.txt and the table of Vk*Flag types in
+        # # appendices/boilerplate.txt.
+        # if pi.begin is None and pi.validity is None and pi.end is None:
+        #     pi.begin = pi.include
+        #     pi.extractPage = False
+        #     pi.Warning = 'No begin, validity, or end lines identified'
+        #     continue
+
+        # Using open block delimiters, ref pages must *always* have a
+        # defined begin and end. If either is undefined, that's fatal.
+        if pi.begin is None:
+            pi.extractPage = False
+            pi.Warning = 'Can\'t identify begin of ref page open block'
+            continue
+
+        if pi.end is None:
+            pi.extractPage = False
+            pi.Warning = 'Can\'t identify end of ref page open block'
+            continue
+
+        # If there's no description of the page, infer one from the type
+        if pi.desc is None:
+            if pi.type is not None:
+                # pi.desc = pi.type[0:len(pi.type)-1] + ' (no short description available)'
+                pi.Warning = 'No short description available; could infer from the type and name'
+            else:
+                pi.extractPage = False
+                pi.Warning = 'No short description available, cannot infer from the type'
+                continue
+
+        # Try to determine where the parameter and body sections of the page
+        # begin. funcpointer, proto, and struct pages infer the location of
+        # the parameter and body sections. Other pages infer the location of
+        # the body, but have no parameter sections.
+        if pi.include is not None:
+            if pi.type in ['funcpointers', 'protos', 'structs']:
+                pi.param = nextPara(file, pi.include)
+                if pi.body is None:
+                    pi.body = nextPara(file, pi.param)
+            else:
+                if pi.body is None:
+                    pi.body = nextPara(file, pi.include)
+        else:
+            pi.Warning = 'Page does not have an API definition include::'
+
+        # It's possible for the inferred param and body lines to run past
+        # the end of block, if, for example, there is no parameter section.
+        pi.param = clampToBlock(pi.param, pi.include, pi.end)
+        pi.body = clampToBlock(pi.body, pi.param, pi.end)
+
+        # We can get to this point with .include, .param, and .validity
+        # all being None, indicating those sections weren't found.
+
+        logDiag('fixupRefs: after processing,', pi.name, 'looks like:')
+        printPageInfo(pi, file)
+
+    # Now that all the valid pages have been found, try to make some
+    # inferences about invalid pages.
+    #
+    # If a reference without a .end is entirely inside a valid reference,
+    # then it's intentionally embedded - may want to create an indirect
+    # page that links into the embedding page. This is done by a very
+    # inefficient double loop, but the loop depth is small.
+    for name in sorted(pageMap.keys()):
+        pi = pageMap[name]
+
+        if pi.end is None:
+            for embedName in sorted(pageMap.keys()):
+                logDiag('fixupRefs: comparing', pi.name, 'to', embedName)
+                embed = pageMap[embedName]
+                # Don't check embeddings which are themselves invalid
+                if not embed.extractPage:
+                    logDiag('Skipping check for embedding in:', embed.name)
+                    continue
+                if embed.begin is None or embed.end is None:
+                    logDiag('fixupRefs:', name + ':',
+                            'can\'t compare to unanchored ref:', embed.name,
+                            'in', specFile, 'at line', pi.include )
+                    printPageInfo(pi, file)
+                    printPageInfo(embed, file)
+                # If an embed is found, change the error to a warning
+                elif (pi.include is not None and pi.include >= embed.begin and
+                      pi.include <= embed.end):
+                    logDiag('fixupRefs: Found embed for:', name,
+                            'inside:', embedName,
+                            'in', specFile, 'at line', pi.include )
+                    pi.embed = embed.name
+                    pi.Warning = 'Embedded in definition for ' + embed.name
+                    break
+                else:
+                    logDiag('fixupRefs: No embed match for:', name,
+                            'inside:', embedName, 'in', specFile,
+                            'at line', pi.include)
+
+
+# Patterns used to recognize interesting lines in an asciidoc source file.
+# These patterns are only compiled once.
+INCSVAR_DEF = re.compile(r':INCS-VAR: (?P<value>.*)')
+endifPat   = re.compile(r'^endif::(?P<condition>[\w_+,]+)\[\]')
+beginPat   = re.compile(r'^\[open,(?P<attribs>refpage=.*)\]')
+# attribute key/value pairs of an open block
+attribStr  = r"([a-z]+)='([^'\\]*(?:\\.[^'\\]*)*)'"
+attribPat  = re.compile(attribStr)
+bodyPat    = re.compile(r'^// *refBody')
+errorPat   = re.compile(r'^// *refError')
+
+# This regex transplanted from check_spec_links
+# It looks for either OpenXR or Vulkan generated file conventions, and for
+# the api/validity include (generated_type), protos/struct/etc path
+# (category), and API name (entity_name). It could be put into the API
+# conventions object.
+INCLUDE = re.compile(
+        r'include::(?P<directory_traverse>((../){1,4}|\{INCS-VAR\}/|\{generated\}/)(generated/)?)(?P<generated_type>[\w]+)/(?P<category>\w+)/(?P<entity_name>[^./]+).txt[\[][\]]')
+
+
+def findRefs(file, filename):
+    """Identify reference pages in a list of strings, returning a dictionary of
+    pageInfo entries for each one found, or None on failure."""
+    setLogSourcefile(filename)
+    setLogProcname('findRefs')
+
+    # To reliably detect the open blocks around reference pages, we must
+    # first detect the '[open,refpage=...]' markup delimiting the block;
+    # skip past the '--' block delimiter on the next line; and identify the
+    # '--' block delimiter closing the page.
+    # This can't be done solely with pattern matching, and requires state to
+    # track 'inside/outside block'.
+    # When looking for open blocks, possible states are:
+    #   'outside' - outside a block
+    #   'start' - have found the '[open...]' line
+    #   'inside' - have found the following '--' line
+    openBlockState = 'outside'
+
+    # Dictionary of interesting line numbers and strings related to an API
+    # name
+    pageMap = {}
+
+    numLines = len(file)
+    line = 0
+
+    # Track the pageInfo object corresponding to the current open block
+    pi = None
+    incsvar = None
+
+    while (line < numLines):
+        setLogLine(line)
+
+        # Look for a file-wide definition
+        matches = INCSVAR_DEF.match(file[line])
+        if matches:
+            incsvar = matches.group('value')
+            logDiag('Matched INCS-VAR definition:', incsvar)
+
+            line = line + 1
+            continue
+
+        # Perform INCS-VAR substitution immediately.
+        if incsvar and '{INCS-VAR}' in file[line]:
+            newLine = file[line].replace('{INCS-VAR}', incsvar)
+            logDiag('PERFORMING SUBSTITUTION', file[line], '->', newLine)
+            file[line] = newLine
+
+        # Only one of the patterns can possibly match. Add it to
+        # the dictionary for that name.
+
+        # [open,refpage=...] starting a refpage block
+        matches = beginPat.search(file[line])
+        if matches is not None:
+            logDiag('Matched open block pattern')
+            attribs = matches.group('attribs')
+
+            # If the previous open block wasn't closed, raise an error
+            if openBlockState != 'outside':
+                logErr('Nested open block starting at line', line, 'of',
+                       filename)
+
+            openBlockState = 'start'
+
+            # Parse the block attributes
+            matches = attribPat.findall(attribs)
+
+            # Extract each attribute
+            name = None
+            desc = None
+            refpage_type = None
+            spec_type = None
+            anchor = None
+            alias = None
+            xrefs = None
+
+            for (key,value) in matches:
+                logDiag('got attribute', key, '=', value)
+                if key == 'refpage':
+                    name = value
+                elif key == 'desc':
+                    desc = unescapeQuotes(value)
+                elif key == 'type':
+                    refpage_type = value
+                elif key == 'spec':
+                    spec_type = value
+                elif key == 'anchor':
+                    anchor = value
+                elif key == 'alias':
+                    alias = value
+                elif key == 'xrefs':
+                    xrefs = value
+                else:
+                    logWarn('unknown open block attribute:', key)
+
+            if name is None or desc is None or refpage_type is None:
+                logWarn('missing one or more required open block attributes:'
+                        'refpage, desc, or type')
+                # Leave pi is None so open block delimiters are ignored
+            else:
+                pi = lookupPage(pageMap, name)
+                pi.desc = desc
+                # Must match later type definitions in interface/validity includes
+                pi.type = refpage_type
+                pi.spec = spec_type
+                pi.anchor = anchor
+                if alias:
+                    pi.alias = alias
+                if xrefs:
+                    pi.refs = xrefs
+                logDiag('open block for', name, 'added DESC =', desc,
+                        'TYPE =', refpage_type, 'ALIAS =', alias,
+                        'XREFS =', xrefs, 'SPEC =', spec_type,
+                        'ANCHOR =', anchor)
+
+            line = line + 1
+            continue
+
+        # '--' starting or ending and open block
+        if file[line].rstrip() == '--':
+            if openBlockState == 'outside':
+                # Only refpage open blocks should use -- delimiters
+                logWarn('Unexpected double-dash block delimiters')
+            elif openBlockState == 'start':
+                # -- delimiter following [open,refpage=...]
+                openBlockState = 'inside'
+
+                if pi is None:
+                    logWarn('no pageInfo available for opening -- delimiter')
+                else:
+                    pi.begin = line + 1
+                    logDiag('opening -- delimiter: added BEGIN =', pi.begin)
+            elif openBlockState == 'inside':
+                # -- delimiter ending an open block
+                if pi is None:
+                    logWarn('no pageInfo available for closing -- delimiter')
+                else:
+                    pi.end = line - 1
+                    logDiag('closing -- delimiter: added END =', pi.end)
+
+                openBlockState = 'outside'
+                pi = None
+            else:
+                logWarn('unknown openBlockState:', openBlockState)
+
+            line = line + 1
+            continue
+
+        matches = INCLUDE.search(file[line])
+        if matches is not None:
+            # Something got included, not sure what yet.
+            gen_type = matches.group('generated_type')
+            refpage_type = matches.group('category')
+            name = matches.group('entity_name')
+
+            # This will never match in OpenCL
+            if gen_type == 'validity':
+                logDiag('Matched validity pattern')
+                if pi is not None:
+                    if pi.type and refpage_type != pi.type:
+                        logWarn('ERROR: pageMap[' + name + '] type:',
+                                pi.type, 'does not match type:', refpage_type)
+                    pi.type = refpage_type
+                    pi.validity = line
+                    logDiag('added TYPE =', pi.type, 'VALIDITY =', pi.validity)
+                else:
+                    logWarn('validity include:: line NOT inside block')
+
+                line = line + 1
+                continue
+
+            if gen_type == 'api':
+                logDiag('Matched include pattern')
+                if pi is not None:
+                    if pi.include is not None:
+                        logDiag('found multiple includes for this block')
+                    if pi.type and refpage_type != pi.type:
+                        logWarn('ERROR: pageMap[' + name + '] type:',
+                                pi.type, 'does not match type:', refpage_type)
+                    pi.type = refpage_type
+                    pi.include = line
+                    logDiag('added TYPE =', pi.type, 'INCLUDE =', pi.include)
+                else:
+                    logWarn('interface include:: line NOT inside block')
+
+                line = line + 1
+                continue
+
+            logDiag('ignoring unrecognized include line ', matches.group())
+
+        # Vulkan 1.1 markup allows the last API include construct to be
+        # followed by an asciidoctor endif:: construct (and also preceded,
+        # at some distance).
+        # This looks for endif:: immediately following an include:: line
+        # and, if found, moves the include boundary to this line.
+        matches = endifPat.search(file[line])
+        if matches is not None and pi is not None:
+            if pi.include == line - 1:
+                logDiag('Matched endif pattern following include; moving include')
+                pi.include = line
+            else:
+                logDiag('Matched endif pattern (not following include)')
+
+            line = line + 1
+            continue
+
+        matches = bodyPat.search(file[line])
+        if matches is not None:
+            logDiag('Matched // refBody pattern')
+            if pi is not None:
+                pi.body = line
+                logDiag('added BODY =', pi.body)
+            else:
+                logWarn('// refBody line NOT inside block')
+
+            line = line + 1
+            continue
+
+        # OpenCL spec uses // refError to tag "validity" (Errors) language,
+        # instead of /validity/ includes.
+        matches = errorPat.search(file[line])
+        if matches is not None:
+            logDiag('Matched // refError pattern')
+            if pi is not None:
+                pi.validity = line
+                logDiag('added VALIDITY (refError) =', pi.validity)
+            else:
+                logWarn('// refError line NOT inside block')
+
+            line = line + 1
+            continue
+
+        line = line + 1
+        continue
+
+    if pi is not None:
+        logErr('Unclosed open block at EOF!')
+
+    setLogSourcefile(None)
+    setLogProcname(None)
+    setLogLine(None)
+
+    return pageMap
+
+
+def getBranch():
+    """Determine current git branch
+
+    Returns (branch name, ''), or (None, stderr output) if the branch name
+    can't be determined"""
+
+    command = [ 'git', 'symbolic-ref', '--short', 'HEAD' ]
+    results = subprocess.run(command,
+                             stdout=subprocess.PIPE,
+                             stderr=subprocess.PIPE)
+
+    # git command failed
+    if len(results.stderr) > 0:
+        return (None, results.stderr)
+
+    # Remove newline from output and convert to a string
+    branch = results.stdout.rstrip().decode()
+    if len(branch) > 0:
+        # Strip trailing newline
+        branch = results.stdout.decode()[0:-1]
+
+    return (branch, '')
--- Vulkan-Headers-1.2.156.orig/registry/spec_tools/attributes.py
+++ Vulkan-Headers-1.2.156/registry/spec_tools/attributes.py
@@ -0,0 +1,114 @@
+#!/usr/bin/python3 -i
+#
+# Copyright (c) 2013-2020 The Khronos Group Inc.
+#
+# SPDX-License-Identifier: Apache-2.0
+"""Utilities for working with attributes of the XML registry."""
+
+import re
+
+_PARAM_REF_NAME_RE = re.compile(
+    r"(?P<name>[\w]+)(?P<brackets>\[\])?(?P<delim>\.|::|->)?")
+
+
+def _split_param_ref(val):
+    return [name for name, _, _ in _PARAM_REF_NAME_RE.findall(val)]
+
+
+def _human_readable_deref(val, make_param_name=None):
+    """Turn the "name[].member[]" notation into plain English."""
+    parts = []
+    matches = _PARAM_REF_NAME_RE.findall(val)
+    for name, brackets, delim in reversed(matches):
+        if make_param_name:
+            name = make_param_name(name)
+        if delim:
+            parts.append('member of')
+        if brackets:
+            parts.append('each element of')
+        parts.append('the')
+        parts.append(name)
+    parts.append('parameter')
+    return ' '.join(parts)
+
+
+class LengthEntry:
+    """An entry in a (comma-separated) len attribute"""
+    NULL_TERMINATED_STRING = 'null-terminated'
+    MATH_STRING = 'latexmath:'
+
+    def __init__(self, val):
+        self.full_reference = val
+        self.other_param_name = None
+        self.null_terminated = False
+        self.number = None
+        self.math = None
+        self.param_ref_parts = None
+        if val == LengthEntry.NULL_TERMINATED_STRING:
+            self.null_terminated = True
+            return
+
+        if val.startswith(LengthEntry.MATH_STRING):
+            self.math = val.replace(LengthEntry.MATH_STRING, '')[1:-1]
+            return
+
+        if val.isdigit():
+            self.number = int(val)
+            return
+
+        # Must be another param name.
+        self.param_ref_parts = _split_param_ref(val)
+        self.other_param_name = self.param_ref_parts[0]
+
+    def __str__(self):
+        return self.full_reference
+
+    def get_human_readable(self, make_param_name=None):
+        assert(self.other_param_name)
+        return _human_readable_deref(self.full_reference, make_param_name=make_param_name)
+
+    def __repr__(self):
+        "Formats an object for repr(), debugger display, etc."
+        return 'spec_tools.attributes.LengthEntry("{}")'.format(self.full_reference)
+
+    @staticmethod
+    def parse_len_from_param(param):
+        """Get a list of LengthEntry."""
+        len_str = param.get('len')
+        if len_str is None:
+            return None
+        return [LengthEntry(elt) for elt in len_str.split(',')]
+
+
+class ExternSyncEntry:
+    """An entry in a (comma-separated) externsync attribute"""
+
+    TRUE_STRING = 'true'
+    TRUE_WITH_CHILDREN_STRING = 'true_with_children'
+
+    def __init__(self, val):
+        self.full_reference = val
+        self.entirely_extern_sync = (val in (ExternSyncEntry.TRUE_STRING, ExternSyncEntry.TRUE_WITH_CHILDREN_STRING))
+        self.children_extern_sync = (val == ExternSyncEntry.TRUE_WITH_CHILDREN_STRING)
+        if self.entirely_extern_sync:
+            return
+
+        self.param_ref_parts = _split_param_ref(val)
+        self.member = self.param_ref_parts[0]
+
+    def get_human_readable(self, make_param_name=None):
+        assert(not self.entirely_extern_sync)
+        return _human_readable_deref(self.full_reference, make_param_name=make_param_name)
+
+    @staticmethod
+    def parse_externsync_from_param(param):
+        """Get a list of ExternSyncEntry."""
+        sync_str = param.get('externsync')
+        if sync_str is None:
+            return None
+        return [ExternSyncEntry(elt) for elt in sync_str.split(',')]
+
+    def __repr__(self):
+        "Formats an object for repr(), debugger display, etc."
+        return 'spec_tools.attributes.ExternSyncEntry("{}")'.format(self.full_reference)
+
--- Vulkan-Headers-1.2.156.orig/registry/spec_tools/validity.py
+++ Vulkan-Headers-1.2.156/registry/spec_tools/validity.py
@@ -0,0 +1,216 @@
+#!/usr/bin/python3 -i
+#
+# Copyright (c) 2013-2020 The Khronos Group Inc.
+#
+# SPDX-License-Identifier: Apache-2.0
+
+import re
+
+
+_A_VS_AN_RE = re.compile(r' a ([a-z]+:)?([aAeEiIoOxX]\w+\b)(?!:)')
+
+_STARTS_WITH_MACRO_RE = re.compile(r'^[a-z]+:.*')
+
+
+def _checkAnchorComponents(anchor):
+    """Raise an exception if any component of a VUID anchor name is illegal."""
+    if anchor:
+        # Any other invalid things in an anchor name should be detected here.
+        if any((' ' in anchor_part for anchor_part in anchor)):
+            raise RuntimeError("Illegal component of a VUID anchor name!")
+
+
+def _fix_a_vs_an(s):
+    """Fix usage (often generated) of the indefinite article 'a' when 'an' is appropriate.
+
+    Explicitly excludes the markup macros."""
+    return _A_VS_AN_RE.sub(r' an \1\2', s)
+
+
+class ValidityCollection:
+    """Combines validity for a single entity."""
+
+    def __init__(self, entity_name=None, conventions=None, strict=True):
+        self.entity_name = entity_name
+        self.conventions = conventions
+        self.lines = []
+        self.strict = strict
+
+    def possiblyAddExtensionRequirement(self, extension_name, entity_preface):
+        """Add an extension-related validity statement if required.
+
+        entity_preface is a string that goes between "must be enabled prior to "
+        and the name of the entity, and normally ends in a macro.
+        For instance, might be "calling flink:" for a function.
+        """
+        if extension_name and not extension_name.startswith(self.conventions.api_version_prefix):
+            msg = 'The {} extension must: be enabled prior to {}{}'.format(
+                self.conventions.formatExtension(extension_name), entity_preface, self.entity_name)
+            self.addValidityEntry(msg, anchor=('extension', 'notenabled'))
+
+    def addValidityEntry(self, msg, anchor=None):
+        """Add a validity entry, optionally with a VUID anchor.
+
+        If any trailing arguments are supplied,
+        an anchor is generated by concatenating them with dashes
+        at the end of the VUID anchor name.
+        """
+        if not msg:
+            raise RuntimeError("Tried to add a blank validity line!")
+        parts = ['*']
+        _checkAnchorComponents(anchor)
+        if anchor:
+            if not self.entity_name:
+                raise RuntimeError('Cannot add a validity entry with an anchor to a collection that does not know its entity name.')
+            parts.append('[[{}]]'.format(
+                '-'.join(['VUID', self.entity_name] + list(anchor))))
+        parts.append(msg)
+        combined = _fix_a_vs_an(' '.join(parts))
+        if combined in self.lines:
+            raise RuntimeError("Duplicate validity added!")
+        self.lines.append(combined)
+
+    def addText(self, msg):
+        """Add already formatted validity text."""
+        if self.strict:
+            raise RuntimeError('addText called when collection in strict mode')
+        if not msg:
+            return
+        msg = msg.rstrip()
+        if not msg:
+            return
+        self.lines.append(msg)
+
+    def _extend(self, lines):
+        lines = list(lines)
+        dupes = set(lines).intersection(self.lines)
+        if dupes:
+            raise RuntimeError("The two sets contain some shared entries! " + str(dupes))
+        self.lines.extend(lines)
+
+    def __iadd__(self, other):
+        """Perform += with a string, iterable, or ValidityCollection."""
+        if other is None:
+            pass
+        elif isinstance(other, str):
+            if self.strict:
+                raise RuntimeError(
+                    'Collection += a string when collection in strict mode')
+            if not other:
+                # empty string
+                pass
+            elif other.startswith('*'):
+                # Handle already-formatted
+                self.addText(other)
+            else:
+                # Do the formatting ourselves.
+                self.addValidityEntry(other)
+        elif isinstance(other, ValidityEntry):
+            if other:
+                if other.verbose:
+                    print(self.entity_name, 'Appending', str(other))
+                self.addValidityEntry(str(other), anchor=other.anchor)
+        elif isinstance(other, ValidityCollection):
+            if not self.entity_name == other.entity_name:
+                raise RuntimeError(
+                    "Trying to combine two ValidityCollections for different entities!")
+            self._extend(other.lines)
+        else:
+            # Deal with other iterables.
+            self._extend(other)
+
+        return self
+
+    def __bool__(self):
+        """Is the collection non-empty?"""
+        empty = not self.lines
+        return not empty
+
+    @property
+    def text(self):
+        """Access validity statements as a single string or None."""
+        if not self.lines:
+            return None
+        return '\n'.join(self.lines) + '\n'
+
+    def __str__(self):
+        """Access validity statements as a single string or empty string."""
+        if not self:
+            return ''
+        return self.text
+
+    def __repr__(self):
+        return '<ValidityCollection: {}>'.format(self.lines)
+
+
+class ValidityEntry:
+    """A single validity line in progress."""
+
+    def __init__(self, text=None, anchor=None):
+        """Prepare to add a validity entry, optionally with a VUID anchor.
+
+        An anchor is generated by concatenating the elements of the anchor tuple with dashes
+        at the end of the VUID anchor name.
+        """
+        _checkAnchorComponents(anchor)
+        if isinstance(anchor, str):
+            # anchor needs to be a tuple
+            anchor = (anchor,)
+
+        # VUID does not allow special chars except ":"
+        if anchor is not None:
+            anchor = [(anchor_value.replace('->', '::').replace('.', '::')) for anchor_value in anchor]
+
+        self.anchor = anchor
+        self.parts = []
+        self.verbose = False
+        if text:
+            self.append(text)
+
+    def append(self, part):
+        """Append a part of a string.
+
+        If this is the first entry part and the part doesn't start
+        with a markup macro, the first character will be capitalized."""
+        if not self.parts and not _STARTS_WITH_MACRO_RE.match(part):
+            self.parts.append(part[:1].upper())
+            self.parts.append(part[1:])
+        else:
+            self.parts.append(part)
+        if self.verbose:
+            print('ValidityEntry', id(self), 'after append:', str(self))
+
+    def drop_end(self, n):
+        """Remove up to n trailing characters from the string."""
+        temp = str(self)
+        n = min(len(temp), n)
+        self.parts = [temp[:-n]]
+
+    def __iadd__(self, other):
+        """Perform += with a string,"""
+        self.append(other)
+        return self
+
+    def __bool__(self):
+        """Return true if we have something more than just an anchor."""
+        empty = not self.parts
+        return not empty
+
+    def __str__(self):
+        """Access validity statement as a single string or empty string."""
+        if not self:
+            raise RuntimeError("No parts added?")
+        return ''.join(self.parts).strip()
+
+    def __repr__(self):
+        parts = ['<ValidityEntry: ']
+        if self:
+            parts.append('"')
+            parts.append(str(self))
+            parts.append('"')
+        else:
+            parts.append('EMPTY')
+        if self.anchor:
+            parts.append(', anchor={}'.format('-'.join(self.anchor)))
+        parts.append('>')
+        return ''.join(parts)
--- Vulkan-Headers-1.2.156.orig/registry/validitygenerator.py
+++ Vulkan-Headers-1.2.156/registry/validitygenerator.py
@@ -0,0 +1,1484 @@
+#!/usr/bin/python3 -i
+#
+# Copyright (c) 2013-2020 The Khronos Group Inc.
+#
+# SPDX-License-Identifier: Apache-2.0
+
+import re
+from collections import OrderedDict, namedtuple
+from functools import reduce
+from pathlib import Path
+
+from conventions import ProseListFormats as plf
+from generator import OutputGenerator, write
+from spec_tools.attributes import ExternSyncEntry, LengthEntry
+from spec_tools.util import (findNamedElem, findNamedObject, findTypedElem,
+                             getElemName, getElemType)
+from spec_tools.validity import ValidityCollection, ValidityEntry
+
+
+# For parsing/splitting queue bit names - Vulkan only
+QUEUE_BITS_RE = re.compile(r'([^,]+)')
+
+
+class UnhandledCaseError(RuntimeError):
+    def __init__(self, msg=None):
+        if msg:
+            super().__init__('Got a case in the validity generator that we have not explicitly handled: ' + msg)
+        else:
+            super().__init__('Got a case in the validity generator that we have not explicitly handled.')
+
+
+def _genericIterateIntersection(a, b):
+    """Iterate through all elements in a that are also in b.
+
+    Somewhat like a set's intersection(),
+    but not type-specific so it can work with OrderedDicts, etc.
+    It also returns a generator instead of a set,
+    so you can pick what container type you'd like,
+    if any.
+    """
+    return (x for x in a if x in b)
+
+
+def _make_ordered_dict(gen):
+    """Make an ordered dict (with None as the values) from a generator."""
+    return OrderedDict(((x, None) for x in gen))
+
+
+def _orderedDictIntersection(a, b):
+    return _make_ordered_dict(_genericIterateIntersection(a, b))
+
+
+def _genericIsDisjoint(a, b):
+    """Return true if nothing in a is also in b.
+
+    Like a set's is_disjoint(),
+    but not type-specific so it can work with OrderedDicts, etc.
+    """
+    for _ in _genericIterateIntersection(a, b):
+        return False
+    # if we never enter the loop...
+    return True
+
+
+def _parse_queue_bits(cmd):
+    """Return a generator of queue bits, with underscores turned to spaces.
+
+    Vulkan-only.
+
+    Return None if the queues attribute is not specified."""
+    queuetypes = cmd.get('queues')
+    if not queuetypes:
+        return None
+    return (qt.replace('_', ' ')
+            for qt in QUEUE_BITS_RE.findall(queuetypes))
+
+
+class ValidityOutputGenerator(OutputGenerator):
+    """ValidityOutputGenerator - subclass of OutputGenerator.
+
+    Generates AsciiDoc includes of valid usage information, for reference
+    pages and the specification. Similar to DocOutputGenerator.
+
+    ---- methods ----
+    ValidityOutputGenerator(errFile, warnFile, diagFile) - args as for
+    OutputGenerator. Defines additional internal state.
+    ---- methods overriding base class ----
+    beginFile(genOpts)
+    endFile()
+    beginFeature(interface, emit)
+    endFeature()
+    genCmd(cmdinfo)
+    """
+
+    def __init__(self, *args, **kwargs):
+        super().__init__(*args, **kwargs)
+
+        self.currentExtension = ''
+
+    @property
+    def null(self):
+        """Preferred spelling of NULL.
+
+        Delegates to the object implementing ConventionsBase.
+        """
+        return self.conventions.null
+
+    @property
+    def structtype_member_name(self):
+        """Return name of the structure type member.
+
+        Delegates to the object implementing ConventionsBase.
+        """
+        return self.conventions.structtype_member_name
+
+    @property
+    def nextpointer_member_name(self):
+        """Return name of the structure pointer chain member.
+
+        Delegates to the object implementing ConventionsBase.
+        """
+        return self.conventions.nextpointer_member_name
+
+    def makeProseList(self, elements, fmt=plf.AND,
+                      comma_for_two_elts=False, *args, **kwargs):
+        """Make a (comma-separated) list for use in prose.
+
+        Adds a connective (by default, 'and')
+        before the last element if there are more than 1.
+
+        Optionally adds a quantifier (like 'any') before a list of 2 or more,
+        if specified by fmt.
+
+        Delegates to the object implementing ConventionsBase.
+        """
+        if not elements:
+            raise ValueError(
+                'Cannot pass an empty list if you are trying to make a prose list.')
+        return self.conventions.makeProseList(elements,
+                                              fmt,
+                                              with_verb=False,
+                                              comma_for_two_elts=comma_for_two_elts,
+                                              *args, **kwargs)
+
+    def makeProseListIs(self, elements, fmt=plf.AND,
+                        comma_for_two_elts=False, *args, **kwargs):
+        """Make a (comma-separated) list for use in prose, followed by either 'is' or 'are' as appropriate.
+
+        Adds a connective (by default, 'and')
+        before the last element if there are more than 1.
+
+        Optionally adds a quantifier (like 'any') before a list of 2 or more,
+        if specified by fmt.
+
+        Delegates to the object implementing ConventionsBase.
+        """
+        if not elements:
+            raise ValueError(
+                'Cannot pass an empty list if you are trying to make a prose list.')
+        return self.conventions.makeProseList(elements,
+                                              fmt,
+                                              with_verb=True,
+                                              comma_for_two_elts=comma_for_two_elts,
+                                              *args, **kwargs)
+
+    def makeValidityCollection(self, entity_name):
+        """Create a ValidityCollection object, passing along our Conventions."""
+        return ValidityCollection(entity_name, self.conventions)
+
+    def beginFile(self, genOpts):
+        if not genOpts.conventions:
+            raise RuntimeError(
+                'Must specify conventions object to generator options')
+        self.conventions = genOpts.conventions
+        # Vulkan says 'must: be a valid pointer' a lot, OpenXR just says
+        # 'must: be a pointer'.
+        self.valid_pointer_text = ' '.join(
+            (x for x in (self.conventions.valid_pointer_prefix, 'pointer') if x))
+        OutputGenerator.beginFile(self, genOpts)
+
+    def endFile(self):
+        OutputGenerator.endFile(self)
+
+    def beginFeature(self, interface, emit):
+        # Start processing in superclass
+        OutputGenerator.beginFeature(self, interface, emit)
+        self.currentExtension = interface.get('name')
+
+    def endFeature(self):
+        # Finish processing in superclass
+        OutputGenerator.endFeature(self)
+
+    @property
+    def struct_macro(self):
+        """Get the appropriate format macro for a structure."""
+        # delegate to conventions
+        return self.conventions.struct_macro
+
+    def makeStructName(self, name):
+        """Prepend the appropriate format macro for a structure to a structure type name."""
+        # delegate to conventions
+        return self.conventions.makeStructName(name)
+
+    def makeParameterName(self, name):
+        """Prepend the appropriate format macro for a parameter/member to a parameter name."""
+        return 'pname:' + name
+
+    def makeBaseTypeName(self, name):
+        """Prepend the appropriate format macro for a 'base type' to a type name."""
+        return 'basetype:' + name
+
+    def makeEnumerationName(self, name):
+        """Prepend the appropriate format macro for an enumeration type to a enum type name."""
+        return 'elink:' + name
+
+    def makeFuncPointerName(self, name):
+        """Prepend the appropriate format macro for a function pointer type to a type name."""
+        return 'tlink:' + name
+
+    def makeExternalTypeName(self, name):
+        """Prepend the appropriate format macro for an external type like uint32_t to a type name."""
+        # delegate to conventions
+        return self.conventions.makeExternalTypeName(name)
+
+    def makeEnumerantName(self, name):
+        """Prepend the appropriate format macro for an enumerate (value) to a enum value name."""
+        return 'ename:' + name
+
+    def writeInclude(self, directory, basename, validity: ValidityCollection,
+                     threadsafety, commandpropertiesentry=None,
+                     successcodes=None, errorcodes=None):
+        """Generate an include file.
+
+        directory - subdirectory to put file in (absolute or relative pathname)
+        basename - base name of the file
+        validity - ValidityCollection to write.
+        threadsafety - List (may be empty) of thread safety statements to write.
+        successcodes - Optional success codes to document.
+        errorcodes - Optional error codes to document.
+        """
+        # Create subdirectory, if needed
+        directory = Path(directory)
+        if not directory.is_absolute():
+            directory = Path(self.genOpts.directory) / directory
+        self.makeDir(str(directory))
+
+        # Create validity file
+        filename = str(directory / (basename + '.txt'))
+        self.logMsg('diag', '# Generating include file:', filename)
+
+        with open(filename, 'w', encoding='utf-8') as fp:
+            write(self.conventions.warning_comment, file=fp)
+
+            # Valid Usage
+            if validity:
+                write('.Valid Usage (Implicit)', file=fp)
+                write('****', file=fp)
+                write(validity, file=fp, end='')
+                write('****', file=fp)
+                write('', file=fp)
+
+            # Host Synchronization
+            if threadsafety:
+                # The heading of this block differs between projects, so an Asciidoc attribute is used.
+                write('.{externsynctitle}', file=fp)
+                write('****', file=fp)
+                write(threadsafety, file=fp, end='')
+                write('****', file=fp)
+                write('', file=fp)
+
+            # Command Properties - contained within a block, to avoid table numbering
+            if commandpropertiesentry:
+                write('.Command Properties', file=fp)
+                write('****', file=fp)
+                write('[options="header", width="100%"]', file=fp)
+                write('|====', file=fp)
+                write('|<<VkCommandBufferLevel,Command Buffer Levels>>|<<vkCmdBeginRenderPass,Render Pass Scope>>|<<VkQueueFlagBits,Supported Queue Types>>|<<synchronization-pipeline-stages-types,Pipeline Type>>', file=fp)
+                write(commandpropertiesentry, file=fp)
+                write('|====', file=fp)
+                write('****', file=fp)
+                write('', file=fp)
+
+            # Success Codes - contained within a block, to avoid table numbering
+            if successcodes or errorcodes:
+                write('.Return Codes', file=fp)
+                write('****', file=fp)
+                if successcodes:
+                    write('ifndef::doctype-manpage[]', file=fp)
+                    write('<<fundamentals-successcodes,Success>>::', file=fp)
+                    write('endif::doctype-manpage[]', file=fp)
+                    write('ifdef::doctype-manpage[]', file=fp)
+                    write('On success, this command returns::', file=fp)
+                    write('endif::doctype-manpage[]', file=fp)
+                    write(successcodes, file=fp)
+                if errorcodes:
+                    write('ifndef::doctype-manpage[]', file=fp)
+                    write('<<fundamentals-errorcodes,Failure>>::', file=fp)
+                    write('endif::doctype-manpage[]', file=fp)
+                    write('ifdef::doctype-manpage[]', file=fp)
+                    write('On failure, this command returns::', file=fp)
+                    write('endif::doctype-manpage[]', file=fp)
+                    write(errorcodes, file=fp)
+                write('****', file=fp)
+                write('', file=fp)
+
+    def paramIsPointer(self, param):
+        """Check if the parameter passed in is a pointer."""
+        tail = param.find('type').tail
+        return tail is not None and '*' in tail
+
+    def paramIsStaticArray(self, param):
+        """Check if the parameter passed in is a static array."""
+        tail = param.find('name').tail
+        return tail and tail[0] == '['
+
+    def paramIsConst(self, param):
+        """Check if the parameter passed in has a type that mentions const."""
+        return param.text is not None and 'const' in param.text
+
+    def staticArrayLength(self, param):
+        """Get the length of a parameter that's been identified as a static array."""
+        paramenumsize = param.find('enum')
+        if paramenumsize is not None:
+            return paramenumsize.text
+            # TODO switch to below when cosmetic changes OK
+            # return self.makeEnumerantName(paramenumsize.text)
+
+        return param.find('name').tail[1:-1]
+
+    def paramIsArray(self, param):
+        """Check if the parameter passed in is a pointer to an array."""
+        return param.get('len') is not None
+
+    def getHandleDispatchableAncestors(self, typename):
+        """Get the ancestors of a handle object."""
+        ancestors = []
+        current = typename
+        while True:
+            current = self.getHandleParent(current)
+            if current is None:
+                return ancestors
+            if self.isHandleTypeDispatchable(current):
+                ancestors.append(current)
+
+    def isHandleTypeDispatchable(self, handlename):
+        """Check if a parent object is dispatchable or not."""
+        handle = self.registry.tree.find(
+            "types/type/[name='" + handlename + "'][@category='handle']")
+        if handle is not None and getElemType(handle) == 'VK_DEFINE_HANDLE':
+            return True
+        else:
+            return False
+
+    def isHandleOptional(self, param, params):
+        # Simple, if it's optional, return true
+        if param.get('optional') is not None:
+            return True
+
+        # If no validity is being generated, it usually means that validity is complex and not absolute, so let's say yes.
+        if param.get('noautovalidity') is not None:
+            return True
+
+        # If the parameter is an array and we haven't already returned, find out if any of the len parameters are optional
+        if self.paramIsArray(param):
+            for length in LengthEntry.parse_len_from_param(param):
+                if not length.other_param_name:
+                    # don't care about constants or "null-terminated"
+                    continue
+
+                other_param = findNamedElem(params, length.other_param_name)
+                if other_param is None:
+                    self.logMsg('warn', length.other_param_name,
+                                'is listed as a length for parameter', param, 'but no such parameter exists')
+                if other_param and other_param.get('optional'):
+                    return True
+
+        return False
+
+    def makeParamValidityPre(self, param, params, selector):
+        """Make the start of an entry for a parameter's validity, including a chunk of text if it is an array."""
+        param_name = getElemName(param)
+        paramtype = getElemType(param)
+
+        # General pre-amble. Check optionality and add stuff.
+        entry = ValidityEntry(anchor=(param_name, 'parameter'))
+
+        # This is for a union member, and the valid member is chosen by an enum selection
+        if selector:
+            selection = param.get('selection')
+
+            entry += 'If {} is {}, '.format(
+                self.makeParameterName(selector),
+                self.makeEnumerantName(selection))
+
+            return entry
+
+        if self.paramIsStaticArray(param):
+            if paramtype != 'char':
+                entry += 'Any given element of '
+            return entry
+
+        is_optional = param.get('optional') is not None and param.get('optional').split(',')[0] == 'true'
+
+        if self.paramIsArray(param) and param.get('len') != LengthEntry.NULL_TERMINATED_STRING:
+            # Find all the parameters that are called out as optional,
+            # so we can document that they might be zero, and the array may be ignored
+            optionallengths = []
+            for length in LengthEntry.parse_len_from_param(param):
+                if not length.other_param_name:
+                    # Only care about length entries that are parameter names
+                    continue
+
+                other_param = findNamedElem(params, length.other_param_name)
+                other_param_optional = (other_param is not None) and (
+                    other_param.get('optional') is not None)
+
+                if other_param is None or not other_param_optional:
+                    # Don't care about not-found params or non-optional params
+                    continue
+
+                if self.paramIsPointer(other_param):
+                    optionallengths.append(
+                        'the value referenced by ' + self.makeParameterName(length.other_param_name))
+                else:
+                    optionallengths.append(
+                        self.makeParameterName(length.other_param_name))
+
+            # Document that these arrays may be ignored if any of the length values are 0
+            if optionallengths or is_optional:
+                entry += 'If '
+            if optionallengths:
+                entry += self.makeProseListIs(optionallengths, fmt=plf.OR)
+                entry += ' not %s, ' % self.conventions.zero
+            # TODO enabling this in OpenXR, as used in Vulkan, causes nonsensical things like
+            # "If pname:propertyCapacityInput is not `0`, and pname:properties is not `NULL`, pname:properties must: be a pointer to an array of pname:propertyCapacityInput slink:XrApiLayerProperties structures"
+            if optionallengths and is_optional:
+                entry += 'and '
+            if is_optional:
+                entry += self.makeParameterName(param_name)
+                # TODO switch when cosmetic changes OK
+                # entry += ' is not {}, '.format(self.null)
+                entry += ' is not `NULL`, '
+            return entry
+
+        if param.get('optional'):
+            # Don't generate this stub for bitflags
+            type_category = self.getTypeCategory(paramtype)
+            is_optional = param.get('optional').split(',')[0] == 'true'
+            if type_category != 'bitmask' and is_optional:
+                if self.paramIsArray(param) or self.paramIsPointer(param):
+                    optional_val = self.null
+                elif type_category == 'handle':
+                    if self.isHandleTypeDispatchable(paramtype):
+                        optional_val = self.null
+                    else:
+                        optional_val = 'dlink:' + self.conventions.api_prefix + 'NULL_HANDLE'
+                else:
+                    optional_val = self.conventions.zero
+
+                entry += 'If {} is not {}, '.format(
+                    self.makeParameterName(param_name),
+                    optional_val)
+            return entry
+
+        # If none of the early returns happened, we at least return an empty
+        # entry with an anchor.
+        return entry
+
+    def createValidationLineForParameterImpl(self, blockname, param, params, typetext, selector, parentname):
+        """Make the generic validity portion used for all parameters.
+
+        May return None if nothing to validate.
+        """
+        if param.get('noautovalidity') is not None:
+            return None
+
+        validity = self.makeValidityCollection(blockname)
+        param_name = getElemName(param)
+        paramtype = getElemType(param)
+
+        entry = self.makeParamValidityPre(param, params, selector)
+
+        # This is for a child member of a union
+        if selector:
+            entry += 'the {} member of {} must: be '.format(self.makeParameterName(param_name), self.makeParameterName(parentname))
+        else:
+            entry += '{} must: be '.format(self.makeParameterName(param_name))
+
+        if self.paramIsStaticArray(param) and paramtype == 'char':
+            # TODO this is a minor hack to determine if this is a command parameter or a struct member
+            if self.paramIsConst(param) or blockname.startswith(self.conventions.type_prefix):
+                entry += 'a null-terminated UTF-8 string whose length is less than or equal to '
+                entry += self.staticArrayLength(param)
+            else:
+                # This is a command's output parameter
+                entry += 'a character array of length %s ' % self.staticArrayLength(param)
+            validity += entry
+            return validity
+
+        elif self.paramIsArray(param):
+            # Arrays. These are hard to get right, apparently
+
+            lengths = LengthEntry.parse_len_from_param(param)
+
+            for i, length in enumerate(LengthEntry.parse_len_from_param(param)):
+                if i == 0:
+                    # If the first index, make it singular.
+                    entry += 'a '
+                    array_text = 'an array'
+                    pointer_text = self.valid_pointer_text
+                else:
+                    array_text = 'arrays'
+                    pointer_text = self.valid_pointer_text + 's'
+
+                if length.null_terminated:
+                    # This should always be the last thing.
+                    # If it ever isn't for some bizarre reason, then this will need some massaging.
+                    entry += 'null-terminated '
+                elif length.number == 1:
+                    entry += pointer_text
+                    entry += ' to '
+                else:
+                    entry += pointer_text
+                    entry += ' to '
+                    entry += array_text
+                    entry += ' of '
+                    # Handle equations, which are currently denoted with latex
+                    if length.math:
+                        # Handle equations, which are currently denoted with latex
+                        entry += str(length)
+                    else:
+                        entry += self.makeParameterName(str(length))
+                    entry += ' '
+
+            # Void pointers don't actually point at anything - remove the word "to"
+            if paramtype == 'void':
+                if lengths[-1].number == 1:
+                    if len(lengths) > 1:
+                        # Take care of the extra s added by the post array chunk function. #HACK#
+                        entry.drop_end(5)
+                    else:
+                        entry.drop_end(4)
+
+                    # This hasn't been hit, so this hasn't been tested recently.
+                    raise UnhandledCaseError(
+                        "Got void pointer param/member with last length 1")
+                else:
+                    # An array of void values is a byte array.
+                    entry += 'byte'
+
+            elif paramtype == 'char':
+                # A null terminated array of chars is a string
+                if lengths[-1].null_terminated:
+                    entry += 'UTF-8 string'
+                else:
+                    # Else it's just a bunch of chars
+                    entry += 'char value'
+
+            elif self.paramIsConst(param):
+                # If a value is "const" that means it won't get modified, so it must be valid going into the function.
+                if 'const' in param.text:
+
+                    if not self.isStructAlwaysValid(paramtype):
+                        entry += 'valid '
+
+            # Check if the array elements are optional
+            array_element_optional = param.get('optional') is not None    \
+                      and len(param.get('optional').split(',')) == len(LengthEntry.parse_len_from_param(param)) + 1 \
+                      and param.get('optional').split(',')[-1] == 'true'
+            if array_element_optional and self.getTypeCategory(paramtype) != 'bitmask': # bitmask is handled later
+                entry += 'or dlink:' + self.conventions.api_prefix + 'NULL_HANDLE '
+
+            entry += typetext
+
+            # pluralize
+            if len(lengths) > 1 or (lengths[0] != 1 and not lengths[0].null_terminated):
+                entry += 's'
+
+            return self.handleRequiredBitmask(blockname, param, paramtype, entry, 'true' if array_element_optional else None)
+
+        if self.paramIsPointer(param):
+            # Handle pointers - which are really special case arrays (i.e. they don't have a length)
+            # TODO  should do something here if someone ever uses some intricate comma-separated `optional`
+            pointercount = param.find('type').tail.count('*')
+
+            # Treat void* as an int
+            if paramtype == 'void':
+                optional = param.get('optional')
+                # If there is only void*, it is just optional int - we don't need any language.
+                if pointercount == 1 and optional is not None:
+                    return None  # early return
+                # Treat the inner-most void* as an int
+                pointercount -= 1
+
+            # Could be multi-level pointers (e.g. ppData - pointer to a pointer). Handle that.
+            entry += 'a '
+            entry += (self.valid_pointer_text + ' to a ') * pointercount
+
+            # Handle void* and pointers to it
+            if paramtype == 'void':
+                if optional is None or optional.split(',')[pointercount]:
+                    # The last void* is just optional int (e.g. to be filled by the impl.)
+                    typetext = 'pointer value'
+
+            # If a value is "const" that means it won't get modified, so it must be valid going into the function.
+            elif self.paramIsConst(param) and paramtype != 'void':
+                entry += 'valid '
+
+            entry += typetext
+            return self.handleRequiredBitmask(blockname, param, paramtype, entry, param.get('optional'))
+
+        # Add additional line for non-optional bitmasks
+        if self.getTypeCategory(paramtype) == 'bitmask':
+            # TODO does not really handle if someone tries something like optional="true,false"
+            # TODO OpenXR has 0 or a valid combination of flags, for optional things.
+            # Vulkan doesn't...
+            # isMandatory = param.get('optional') is None
+            # if not isMandatory:
+            #     entry += self.conventions.zero
+            #     entry += ' or '
+            # Non-pointer, non-optional things must be valid
+            entry += 'a valid {}'.format(typetext)
+
+            return self.handleRequiredBitmask(blockname, param, paramtype, entry, param.get('optional'))
+
+        # Non-pointer, non-optional things must be valid
+        entry += 'a valid {}'.format(typetext)
+        return entry
+
+    def handleRequiredBitmask(self, blockname, param, paramtype, entry, optional):
+        # TODO does not really handle if someone tries something like optional="true,false"
+        if self.getTypeCategory(paramtype) != 'bitmask' or optional == 'true':
+            return entry
+        if self.paramIsPointer(param) and not self.paramIsArray(param):
+            # This is presumably an output parameter
+            return entry
+
+        param_name = getElemName(param)
+        # If mandatory, then we need two entries instead of just one.
+        validity = self.makeValidityCollection(blockname)
+        validity += entry
+
+        entry2 = ValidityEntry(anchor=(param_name, 'requiredbitmask'))
+        if self.paramIsArray(param):
+            entry2 += 'Each element of '
+        entry2 += '{} must: not be {}'.format(
+            self.makeParameterName(param_name), self.conventions.zero)
+        validity += entry2
+        return validity
+
+    def createValidationLineForParameter(self, blockname, param, params, typecategory, selector, parentname):
+        """Make an entire validation entry for a given parameter."""
+        param_name = getElemName(param)
+        paramtype = getElemType(param)
+
+        is_array = self.paramIsArray(param)
+        is_pointer = self.paramIsPointer(param)
+        needs_recursive_validity = (is_array
+                                    or is_pointer
+                                    or not self.isStructAlwaysValid(paramtype))
+        typetext = None
+        if paramtype in ('void', 'char'):
+            # Chars and void are special cases - we call the impl function,
+            # but don't use the typetext.
+            # A null-terminated char array is a string, else it's chars.
+            # An array of void values is a byte array, a void pointer is just a pointer to nothing in particular
+            typetext = ''
+
+        elif typecategory == 'bitmask':
+            bitsname = paramtype.replace('Flags', 'FlagBits')
+            bitselem = self.registry.tree.find("enums[@name='" + bitsname + "']")
+
+            # If bitsname is an alias, then use the alias to get bitselem.
+            typeElem = self.registry.lookupElementInfo(bitsname, self.registry.typedict)
+            if typeElem is not None:
+                alias = self.registry.getAlias(typeElem.elem, self.registry.typedict)
+                if alias is not None:
+                    bitselem = self.registry.tree.find("enums[@name='" + alias + "']")
+
+            if bitselem is None or len(bitselem.findall('enum[@required="true"]')) == 0:
+                # Empty bit mask: presumably just a placeholder (or only in
+                # an extension not enabled for this build)
+                entry = ValidityEntry(
+                    anchor=(param_name, 'zerobitmask'))
+                entry += self.makeParameterName(param_name)
+                entry += ' must: be '
+                entry += self.conventions.zero
+                # Early return
+                return entry
+
+            is_const = self.paramIsConst(param)
+
+            if is_array:
+                if is_const:
+                    # input an array of bitmask values
+                    template = 'combinations of {bitsname} value'
+                else:
+                    template = '{paramtype} value'
+            elif is_pointer:
+                if is_const:
+                    template = 'combination of {bitsname} values'
+                else:
+                    template = '{paramtype} value'
+            else:
+                template = 'combination of {bitsname} values'
+
+            # The above few cases all use makeEnumerationName, just with different context.
+            typetext = template.format(
+                bitsname=self.makeEnumerationName(bitsname),
+                paramtype=self.makeEnumerationName(paramtype))
+
+        elif typecategory == 'handle':
+            typetext = '{} handle'.format(self.makeStructName(paramtype))
+
+        elif typecategory == 'enum':
+            typetext = '{} value'.format(self.makeEnumerationName(paramtype))
+
+        elif typecategory == 'funcpointer':
+            typetext = '{} value'.format(self.makeFuncPointerName(paramtype))
+
+        elif typecategory == 'struct':
+            if needs_recursive_validity:
+                typetext = '{} structure'.format(
+                    self.makeStructName(paramtype))
+
+        elif typecategory == 'union':
+            if needs_recursive_validity:
+                typetext = '{} union'.format(self.makeStructName(paramtype))
+
+        elif self.paramIsArray(param) or self.paramIsPointer(param):
+            # TODO sync cosmetic changes from OpenXR?
+            typetext = '{} value'.format(self.makeBaseTypeName(paramtype))
+
+        elif typecategory is None:
+            if not self.isStructAlwaysValid(paramtype):
+                typetext = '{} value'.format(
+                    self.makeExternalTypeName(paramtype))
+
+            # "a valid uint32_t value" doesn't make much sense.
+            pass
+
+        # If any of the above conditions matched and set typetext,
+        # we call using it.
+        if typetext is not None:
+            return self.createValidationLineForParameterImpl(
+                blockname, param, params, typetext, selector, parentname)
+        return None
+
+    def makeHandleValidityParent(self, param, params):
+        """Make a validity entry for a handle's parent object.
+
+        Creates 'parent' VUID.
+        """
+        param_name = getElemName(param)
+        paramtype = getElemType(param)
+
+        # Deal with handle parents
+        handleparent = self.getHandleParent(paramtype)
+        if handleparent is None:
+            return None
+
+        otherparam = findTypedElem(params, handleparent)
+        if otherparam is None:
+            return None
+
+        parent_name = getElemName(otherparam)
+        entry = ValidityEntry(anchor=(param_name, 'parent'))
+
+        is_optional = self.isHandleOptional(param, params)
+
+        if self.paramIsArray(param):
+            template = 'Each element of {}'
+            if is_optional:
+                template += ' that is a valid handle'
+        elif is_optional:
+            template = 'If {} is a valid handle, it'
+        else:
+            # not optional, not an array. Just say the parameter name.
+            template = '{}'
+
+        entry += template.format(self.makeParameterName(param_name))
+
+        entry += ' must: have been created, allocated, or retrieved from {}'.format(
+            self.makeParameterName(parent_name))
+
+        return entry
+
+    def makeAsciiDocHandlesCommonAncestor(self, blockname, handles, params):
+        """Make an asciidoc validity entry for a common ancestors between handles.
+
+        Only handles parent validity for signatures taking multiple handles
+        any ancestors also being supplied to this function.
+        (e.g. "Each of x, y, and z must: come from the same slink:ParentHandle")
+        See self.makeAsciiDocHandleParent() for instances where the parent
+        handle is named and also passed.
+
+        Creates 'commonparent' VUID.
+        """
+        # TODO Replace with refactored code from OpenXR
+        entry = None
+
+        if len(handles) > 1:
+            ancestormap = {}
+            anyoptional = False
+            # Find all the ancestors
+            for param in handles:
+                paramtype = getElemType(param)
+
+                if not self.paramIsPointer(param) or (param.text and 'const' in param.text):
+                    ancestors = self.getHandleDispatchableAncestors(paramtype)
+
+                    ancestormap[param] = ancestors
+
+                    anyoptional |= self.isHandleOptional(param, params)
+
+            # Remove redundant ancestor lists
+            for param in handles:
+                paramtype = getElemType(param)
+
+                removals = []
+                for ancestors in ancestormap.items():
+                    if paramtype in ancestors[1]:
+                        removals.append(ancestors[0])
+
+                if removals != []:
+                    for removal in removals:
+                        del(ancestormap[removal])
+
+            # Intersect
+
+            if len(ancestormap.values()) > 1:
+                current = list(ancestormap.values())[0]
+                for ancestors in list(ancestormap.values())[1:]:
+                    current = [val for val in current if val in ancestors]
+
+                if len(current) > 0:
+                    commonancestor = current[0]
+
+                    if len(ancestormap.keys()) > 1:
+
+                        entry = ValidityEntry(anchor=('commonparent',))
+
+                        parametertexts = []
+                        for param in ancestormap.keys():
+                            param_name = getElemName(param)
+                            parametertext = self.makeParameterName(param_name)
+                            if self.paramIsArray(param):
+                                parametertext = 'the elements of ' + parametertext
+                            parametertexts.append(parametertext)
+
+                        parametertexts.sort()
+
+                        if len(parametertexts) > 2:
+                            entry += 'Each of '
+                        else:
+                            entry += 'Both of '
+
+                        entry += self.makeProseList(parametertexts,
+                                                    comma_for_two_elts=True)
+                        if anyoptional is True:
+                            entry += ' that are valid handles of non-ignored parameters'
+                        entry += ' must: have been created, allocated, or retrieved from the same '
+                        entry += self.makeStructName(commonancestor)
+
+        return entry
+
+    def makeStructureTypeFromName(self, structname):
+        """Create text for a structure type name, like ename:VK_STRUCTURE_TYPE_CREATE_INSTANCE_INFO"""
+        return self.makeEnumerantName(self.conventions.generate_structure_type_from_name(structname))
+
+    def makeStructureTypeValidity(self, structname):
+        """Generate an validity line for the type value of a struct.
+
+        Creates VUID named like the member name.
+        """
+        info = self.registry.typedict.get(structname)
+        assert(info is not None)
+
+        # If this fails (meaning we have something other than a struct in here),
+        # then the caller is wrong:
+        # probably passing the wrong value for structname.
+        members = info.getMembers()
+        assert(members)
+
+        # If this fails, see caller: this should only get called for a struct type with a type value.
+        param = findNamedElem(members, self.structtype_member_name)
+        # OpenXR gets some structs without a type field in here, so can't assert
+        assert(param is not None)
+        # if param is None:
+        #     return None
+
+        entry = ValidityEntry(
+            anchor=(self.structtype_member_name, self.structtype_member_name))
+        entry += self.makeParameterName(self.structtype_member_name)
+        entry += ' must: be '
+
+        values = param.get('values', '').split(',')
+        if values:
+            # Extract each enumerant value. They could be validated in the
+            # same fashion as validextensionstructs in
+            # makeStructureExtensionPointer, although that's not relevant in
+            # the current extension struct model.
+            entry += self.makeProseList((self.makeEnumerantName(v)
+                                         for v in values), 'or')
+            return entry
+
+        if 'Base' in structname:
+            # This type doesn't even have any values for its type,
+            # and it seems like it might be a base struct that we'd expect to lack its own type,
+            # so omit the entire statement
+            return None
+
+        self.logMsg('warn', 'No values were marked-up for the structure type member of',
+                    structname, 'so making one up!')
+        entry += self.makeStructureTypeFromName(structname)
+
+        return entry
+
+    def makeStructureExtensionPointer(self, blockname, param):
+        """Generate an validity line for the pointer chain member value of a struct."""
+        param_name = getElemName(param)
+
+        if param.get('validextensionstructs') is not None:
+            self.logMsg('warn', blockname,
+                        'validextensionstructs is deprecated/removed', '\n')
+
+        entry = ValidityEntry(
+            anchor=(param_name, self.nextpointer_member_name))
+        validextensionstructs = self.registry.validextensionstructs.get(
+            blockname)
+        extensionstructs = []
+        duplicatestructs = []
+
+        if validextensionstructs is not None:
+            # Check each structure name and skip it if not required by the
+            # generator. This allows tagging extension structs in the XML
+            # that are only included in validity when needed for the spec
+            # being targeted.
+            # Track the required structures, and of the required structures,
+            # those that allow duplicates in the pNext chain.
+            for struct in validextensionstructs:
+                # Unpleasantly breaks encapsulation. Should be a method in the registry class
+                t = self.registry.lookupElementInfo(
+                    struct, self.registry.typedict)
+                if t is None:
+                    self.logMsg('warn', 'makeStructureExtensionPointer: struct', struct,
+                                'is in a validextensionstructs= attribute but is not in the registry')
+                elif t.required:
+                    extensionstructs.append('slink:' + struct)
+                    if t.elem.get('allowduplicate') == 'true':
+                        duplicatestructs.append('slink:' + struct)
+                else:
+                    self.logMsg(
+                        'diag', 'makeStructureExtensionPointer: struct', struct, 'IS NOT required')
+
+        if not extensionstructs:
+            entry += '{} must: be {}'.format(
+                self.makeParameterName(param_name), self.null)
+            return entry
+
+        if len(extensionstructs) == 1:
+            entry += '{} must: be {} or a pointer to a valid instance of {}'.format(self.makeParameterName(param_name), self.null,
+                                                                                    extensionstructs[0])
+        else:
+            # More than one extension struct.
+            entry += 'Each {} member of any structure (including this one) in the pname:{} chain '.format(
+                self.makeParameterName(param_name), self.nextpointer_member_name)
+            entry += 'must: be either {} or a pointer to a valid instance of '.format(
+                self.null)
+
+            entry += self.makeProseList(extensionstructs, fmt=plf.OR)
+
+        validity = self.makeValidityCollection(blockname)
+        validity += entry
+
+        # Generate VU statement requiring unique structures in the pNext
+        # chain.
+        # NOTE: OpenXR always allows non-unique type values. Instances other
+        # than the first are just ignored
+
+        vu = ('The pname:' +
+              self.structtype_member_name +
+              ' value of each struct in the pname:' +
+              self.nextpointer_member_name +
+              ' chain must: be unique')
+        anchor = (self.conventions.member_used_for_unique_vuid, 'unique')
+
+        # If duplicates of some structures are allowed, they are called out
+        # explicitly.
+        num = len(duplicatestructs)
+        if num > 0:
+            vu = (vu +
+                  ', with the exception of structures of type ' +
+                  self.makeProseList(duplicatestructs, fmt=plf.OR))
+
+        validity.addValidityEntry(vu, anchor = anchor )
+
+        return validity
+
+    def addSharedStructMemberValidity(self, struct, blockname, param, validity):
+        """Generate language to independently validate a parameter, for those validated even in output.
+
+        Return value indicates whether it was handled internally (True) or if it may need more validity (False)."""
+        param_name = getElemName(param)
+        paramtype = getElemType(param)
+        if param.get('noautovalidity') is None:
+
+            if self.conventions.is_structure_type_member(paramtype, param_name):
+                validity += self.makeStructureTypeValidity(blockname)
+                return True
+
+            if self.conventions.is_nextpointer_member(paramtype, param_name):
+                # Vulkan: the addition of validity here is conditional unlike OpenXR.
+                if struct.get('structextends') is None:
+                    validity += self.makeStructureExtensionPointer(
+                        blockname, param)
+                return True
+        return False
+
+    def makeOutputOnlyStructValidity(self, cmd, blockname, params):
+        """Generate all the valid usage information for a struct that's entirely output.
+
+        That is, it is only ever filled out by the implementation other than
+        the structure type and pointer chain members.
+        Thus, we only create validity for the pointer chain member.
+        """
+        # Start the validity collection for this struct
+        validity = self.makeValidityCollection(blockname)
+
+        for param in params:
+            self.addSharedStructMemberValidity(
+                cmd, blockname, param, validity)
+
+        return validity
+
+    def makeStructOrCommandValidity(self, cmd, blockname, params):
+        """Generate all the valid usage information for a given struct or command."""
+        validity = self.makeValidityCollection(blockname)
+        handles = []
+        arraylengths = dict()
+        for param in params:
+            param_name = getElemName(param)
+            paramtype = getElemType(param)
+
+            # Valid usage ID tags (VUID) are generated for various
+            # conditions based on the name of the block (structure or
+            # command), name of the element (member or parameter), and type
+            # of VU statement.
+
+            # Get the type's category
+            typecategory = self.getTypeCategory(paramtype)
+
+            if not self.addSharedStructMemberValidity(
+                    cmd, blockname, param, validity):
+                if not param.get('selector'):
+                    validity += self.createValidationLineForParameter(
+                        blockname, param, params, typecategory, None, None)
+                else:
+                    selector = param.get('selector')
+                    if typecategory != 'union':
+                        self.logMsg('warn', 'selector attribute set on non-union parameter', param_name, 'in', blockname)
+
+                    paraminfo = self.registry.lookupElementInfo(paramtype, self.registry.typedict)
+
+                    for member in paraminfo.getMembers():
+                        membertype = getElemType(member)
+                        membertypecategory = self.getTypeCategory(membertype)
+
+                        validity += self.createValidationLineForParameter(
+                            blockname, member, paraminfo.getMembers(), membertypecategory, selector, param_name)
+
+            # Ensure that any parenting is properly validated, and list that a handle was found
+            if typecategory == 'handle':
+                handles.append(param)
+
+            # Get the array length for this parameter
+            lengths = LengthEntry.parse_len_from_param(param)
+            if lengths:
+                arraylengths.update({length.other_param_name: length
+                                     for length in lengths
+                                     if length.other_param_name})
+
+        # For any vkQueue* functions, there might be queue type data
+        if 'vkQueue' in blockname:
+            # The queue type must be valid
+            queuebits = _parse_queue_bits(cmd)
+            if queuebits:
+                entry = ValidityEntry(anchor=('queuetype',))
+                entry += 'The pname:queue must: support '
+                entry += self.makeProseList(queuebits,
+                                            fmt=plf.OR, comma_for_two_elts=True)
+                entry += ' operations'
+                validity += entry
+
+        if 'vkCmd' in blockname:
+            # The commandBuffer parameter must be being recorded
+            entry = ValidityEntry(anchor=('commandBuffer', 'recording'))
+            entry += 'pname:commandBuffer must: be in the <<commandbuffers-lifecycle, recording state>>'
+            validity += entry
+
+            #
+            # Start of valid queue type validation - command pool must have been
+            # allocated against a queue with at least one of the valid queue types
+            entry = ValidityEntry(anchor=('commandBuffer', 'cmdpool'))
+
+            #
+            # This test for vkCmdFillBuffer is a hack, since we have no path
+            # to conditionally have queues enabled or disabled by an extension.
+            # As the VU stuff is all moving out (hopefully soon), this hack solves the issue for now
+            if blockname == 'vkCmdFillBuffer':
+                entry += 'The sname:VkCommandPool that pname:commandBuffer was allocated from must: support '
+                if 'VK_KHR_maintenance1' in self.registry.requiredextensions:
+                    entry += 'transfer, graphics or compute operations'
+                else:
+                    entry += 'graphics or compute operations'
+            else:
+                # The queue type must be valid
+                queuebits = _parse_queue_bits(cmd)
+                assert(queuebits)
+                entry += 'The sname:VkCommandPool that pname:commandBuffer was allocated from must: support '
+                entry += self.makeProseList(queuebits,
+                                            fmt=plf.OR, comma_for_two_elts=True)
+                entry += ' operations'
+            validity += entry
+
+            # Must be called inside/outside a renderpass appropriately
+            renderpass = cmd.get('renderpass')
+
+            if renderpass != 'both':
+                entry = ValidityEntry(anchor=('renderpass',))
+                entry += 'This command must: only be called '
+                entry += renderpass
+                entry += ' of a render pass instance'
+                validity += entry
+
+            # Must be in the right level command buffer
+            cmdbufferlevel = cmd.get('cmdbufferlevel')
+
+            if cmdbufferlevel != 'primary,secondary':
+                entry = ValidityEntry(anchor=('bufferlevel',))
+                entry += 'pname:commandBuffer must: be a '
+                entry += cmdbufferlevel
+                entry += ' sname:VkCommandBuffer'
+                validity += entry
+
+        # Any non-optional arraylengths should specify they must be greater than 0
+        array_length_params = ((param, getElemName(param))
+                               for param in params
+                               if getElemName(param) in arraylengths)
+
+        for param, param_name in array_length_params:
+            if param.get('optional') is not None:
+                continue
+
+            length = arraylengths[param_name]
+            full_length = length.full_reference
+
+            # Is this just a name of a param? If false, then it's some kind of qualified name (a member of a param for instance)
+            simple_param_reference = (len(length.param_ref_parts) == 1)
+            if not simple_param_reference:
+                # Loop through to see if any parameters in the chain are optional
+                array_length_parent = cmd
+                array_length_optional = False
+                for part in length.param_ref_parts:
+                    # Overwrite the param so it ends up as the bottom level parameter for later checks
+                    param = array_length_parent.find("*/[name='{}']".format(part))
+
+                    # If any parameter in the chain is optional, skip the implicit length requirement
+                    array_length_optional |= (param.get('optional') is not None)
+
+                    # Lookup the type of the parameter for the next loop iteration
+                    type = param.findtext('type')
+                    array_length_parent = self.registry.tree.find("./types/type/[@name='{}']".format(type))
+
+                if array_length_optional:
+                    continue
+
+            # Get all the array dependencies
+            arrays = cmd.findall(
+                "param/[@len='{}'][@optional='true']".format(full_length))
+
+            # Get all the optional array dependencies, including those not generating validity for some reason
+            optionalarrays = arrays + \
+                cmd.findall(
+                    "param/[@len='{}'][@noautovalidity='true']".format(full_length))
+
+            entry = ValidityEntry(anchor=(full_length, 'arraylength'))
+            # Allow lengths to be arbitrary if all their dependents are optional
+            if optionalarrays and len(optionalarrays) == len(arrays):
+                entry += 'If '
+                # TODO sync this section from OpenXR once cosmetic changes OK
+
+                optional_array_names = (self.makeParameterName(getElemName(array))
+                                        for array in optionalarrays)
+                entry += self.makeProseListIs(optional_array_names,
+                                              plf.ANY_OR, comma_for_two_elts=True)
+
+                entry += ' not {}, '.format(self.null)
+
+            # TODO end needs sync cosmetic
+            if self.paramIsPointer(param):
+                entry += 'the value referenced by '
+
+            # Split and re-join here to insert pname: around ::
+            entry += '::'.join(self.makeParameterName(part)
+                               for part in full_length.split('::'))
+            # TODO replace the previous statement with the following when cosmetic changes OK
+            # entry += length.get_human_readable(make_param_name=self.makeParameterName)
+
+            entry += ' must: be greater than '
+            entry += self.conventions.zero
+            validity += entry
+
+        # Find the parents of all objects referenced in this command
+        for param in handles:
+            # Don't detect a parent for return values!
+            if not self.paramIsPointer(param) or self.paramIsConst(param):
+                validity += self.makeHandleValidityParent(param, params)
+
+        # Find the common ancestor of all objects referenced in this command
+        validity += self.makeAsciiDocHandlesCommonAncestor(
+            blockname, handles, params)
+
+        return validity
+
+    def makeThreadSafetyBlock(self, cmd, paramtext):
+        """Generate thread-safety validity entries for cmd/structure"""
+        # See also makeThreadSafetyBlock in validitygenerator.py
+        validity = self.makeValidityCollection(getElemName(cmd))
+
+        # This text varies between projects, so an Asciidoctor attribute is used.
+        extsync_prefix = "{externsyncprefix} "
+
+        # Find and add any parameters that are thread unsafe
+        explicitexternsyncparams = cmd.findall(paramtext + "[@externsync]")
+        if explicitexternsyncparams is not None:
+            for param in explicitexternsyncparams:
+                externsyncattribs = ExternSyncEntry.parse_externsync_from_param(
+                    param)
+                param_name = getElemName(param)
+
+                for attrib in externsyncattribs:
+                    entry = ValidityEntry()
+                    entry += extsync_prefix
+                    if attrib.entirely_extern_sync:
+                        if self.paramIsArray(param):
+                            entry += 'each member of '
+                        elif self.paramIsPointer(param):
+                            entry += 'the object referenced by '
+
+                        entry += self.makeParameterName(param_name)
+
+                        if attrib.children_extern_sync:
+                            entry += ', and any child handles,'
+
+                    else:
+                        entry += 'pname:'
+                        entry += str(attrib.full_reference)
+                        # TODO switch to the following when cosmetic changes OK
+                        # entry += attrib.get_human_readable(make_param_name=self.makeParameterName)
+                    entry += ' must: be externally synchronized'
+                    validity += entry
+
+        # Vulkan-specific
+        # For any vkCmd* functions, the command pool is externally synchronized
+        if cmd.find('proto/name') is not None and 'vkCmd' in cmd.find('proto/name').text:
+            entry = ValidityEntry()
+            entry += extsync_prefix
+            entry += 'the sname:VkCommandPool that pname:commandBuffer was allocated from must: be externally synchronized'
+            validity += entry
+
+        # Find and add any "implicit" parameters that are thread unsafe
+        implicitexternsyncparams = cmd.find('implicitexternsyncparams')
+        if implicitexternsyncparams is not None:
+            for elem in implicitexternsyncparams:
+                entry = ValidityEntry()
+                entry += extsync_prefix
+                entry += elem.text
+                entry += ' must: be externally synchronized'
+                validity += entry
+
+        return validity
+
+    def makeCommandPropertiesTableEntry(self, cmd, name):
+
+        if 'vkCmd' in name:
+            # Must be called inside/outside a renderpass appropriately
+            cmdbufferlevel = cmd.get('cmdbufferlevel')
+            cmdbufferlevel = (' + \n').join(cmdbufferlevel.title().split(','))
+
+            renderpass = cmd.get('renderpass')
+            renderpass = renderpass.capitalize()
+
+            #
+            # This test for vkCmdFillBuffer is a hack, since we have no path
+            # to conditionally have queues enabled or disabled by an extension.
+            # As the VU stuff is all moving out (hopefully soon), this hack solves the issue for now
+            if name == 'vkCmdFillBuffer':
+                if 'VK_KHR_maintenance1' in self.registry.requiredextensions:
+                    queues = 'Transfer + \nGraphics + \nCompute'
+                else:
+                    queues = 'Graphics + \nCompute'
+            else:
+                queues = cmd.get('queues')
+                queues = (' + \n').join(queues.title().split(','))
+
+            pipeline = cmd.get('pipeline')
+            if pipeline:
+                pipeline = pipeline.capitalize()
+            else:
+                pipeline = ''
+
+            return '|' + cmdbufferlevel + '|' + renderpass + '|' + queues + '|' + pipeline
+        elif 'vkQueue' in name:
+            # Must be called inside/outside a renderpass appropriately
+
+            queues = cmd.get('queues')
+            if queues is None:
+                queues = 'Any'
+            else:
+                queues = (' + \n').join(queues.upper().split(','))
+
+            return '|-|-|' + queues + '|-'
+
+        return None
+
+
+    def findRequiredEnums(self, enums):
+        """Check each enumerant name in the enums list and remove it if not
+        required by the generator. This allows specifying success and error
+        codes for extensions that are only included in validity when needed
+        for the spec being targeted."""
+        return self.keepOnlyRequired(enums, self.registry.enumdict)
+
+    def findRequiredCommands(self, commands):
+        """Check each command name in the commands list and remove it if not
+        required by the generator.
+
+        This will allow some state operations to take place before endFile."""
+        return self.keepOnlyRequired(commands, self.registry.cmddict)
+
+    def keepOnlyRequired(self, names, info_dict):
+        """Check each element name in the supplied dictionary and remove it if not
+        required by the generator.
+
+        This will allow some operations to take place before endFile no matter the order of generation."""
+        # TODO Unpleasantly breaks encapsulation. Should be a method in the registry class
+
+        def is_required(name):
+            info = self.registry.lookupElementInfo(name, info_dict)
+            if info is None:
+                return False
+            if not info.required:
+                self.logMsg('diag', 'keepOnlyRequired: element',
+                            name, 'IS NOT required, skipping')
+            return info.required
+
+        return [name
+                for name in names
+                if is_required(name)]
+
+    def makeReturnCodeList(self, attrib, cmd, name):
+        """Return a list of possible return codes for a function.
+
+        attrib is either 'successcodes' or 'errorcodes'.
+        """
+        return_lines = []
+        RETURN_CODE_FORMAT = '* ename:{}'
+
+        codes_attr = cmd.get(attrib)
+        if codes_attr:
+            codes = self.findRequiredEnums(codes_attr.split(','))
+            if codes:
+                return_lines.extend((RETURN_CODE_FORMAT.format(code)
+                                     for code in codes))
+
+        applicable_ext_codes = (ext_code
+                                for ext_code in self.registry.commandextensionsuccesses
+                                if ext_code.command == name)
+        for ext_code in applicable_ext_codes:
+            line = RETURN_CODE_FORMAT.format(ext_code.value)
+            if ext_code.extension:
+                line += ' [only if {} is enabled]'.format(
+                    self.conventions.formatExtension(ext_code.extension))
+
+            return_lines.append(line)
+        if return_lines:
+            return '\n'.join(return_lines)
+
+        return None
+
+    def makeSuccessCodes(self, cmd, name):
+        return self.makeReturnCodeList('successcodes', cmd, name)
+
+    def makeErrorCodes(self, cmd, name):
+        return self.makeReturnCodeList('errorcodes', cmd, name)
+
+    def genCmd(self, cmdinfo, name, alias):
+        """Command generation."""
+        OutputGenerator.genCmd(self, cmdinfo, name, alias)
+
+        # @@@ (Jon) something needs to be done here to handle aliases, probably
+
+        validity = self.makeValidityCollection(name)
+
+        # OpenXR-only: make sure extension is enabled
+        # validity.possiblyAddExtensionRequirement(self.currentExtension, 'calling flink:')
+
+        validity += self.makeStructOrCommandValidity(
+            cmdinfo.elem, name, cmdinfo.getParams())
+
+        threadsafety = self.makeThreadSafetyBlock(cmdinfo.elem, 'param')
+        commandpropertiesentry = None
+
+        # Vulkan-specific
+        commandpropertiesentry = self.makeCommandPropertiesTableEntry(
+            cmdinfo.elem, name)
+        successcodes = self.makeSuccessCodes(cmdinfo.elem, name)
+        errorcodes = self.makeErrorCodes(cmdinfo.elem, name)
+
+        # OpenXR-specific
+        # self.generateStateValidity(validity, name)
+
+        self.writeInclude('protos', name, validity, threadsafety,
+                          commandpropertiesentry, successcodes, errorcodes)
+
+    def genStruct(self, typeinfo, typeName, alias):
+        """Struct Generation."""
+        OutputGenerator.genStruct(self, typeinfo, typeName, alias)
+
+        # @@@ (Jon) something needs to be done here to handle aliases, probably
+
+        # Anything that's only ever returned can't be set by the user, so shouldn't have any validity information.
+        validity = self.makeValidityCollection(typeName)
+        threadsafety = []
+
+        # OpenXR-only: make sure extension is enabled
+        # validity.possiblyAddExtensionRequirement(self.currentExtension, 'using slink:')
+
+        if typeinfo.elem.get('category') != 'union':
+            if typeinfo.elem.get('returnedonly') is None:
+                validity += self.makeStructOrCommandValidity(
+                    typeinfo.elem, typeName, typeinfo.getMembers())
+                threadsafety = self.makeThreadSafetyBlock(typeinfo.elem, 'member')
+
+            else:
+                # Need to generate structure type and next pointer chain member validation
+                validity += self.makeOutputOnlyStructValidity(
+                    typeinfo.elem, typeName, typeinfo.getMembers())
+
+        self.writeInclude('structs', typeName, validity,
+                          threadsafety, None, None, None)
+
+    def genGroup(self, groupinfo, groupName, alias):
+        """Group (e.g. C "enum" type) generation.
+        For the validity generator, this just tags individual enumerants
+        as required or not.
+        """
+        OutputGenerator.genGroup(self, groupinfo, groupName, alias)
+
+        # @@@ (Jon) something needs to be done here to handle aliases, probably
+
+        groupElem = groupinfo.elem
+
+        # Loop over the nested 'enum' tags. Keep track of the minimum and
+        # maximum numeric values, if they can be determined; but only for
+        # core API enumerants, not extension enumerants. This is inferred
+        # by looking for 'extends' attributes.
+        for elem in groupElem.findall('enum'):
+            name = elem.get('name')
+            ei = self.registry.lookupElementInfo(name, self.registry.enumdict)
+
+            # Tag enumerant as required or not
+            ei.required = self.isEnumRequired(elem)
+
+    def genType(self, typeinfo, name, alias):
+        """Type Generation."""
+        OutputGenerator.genType(self, typeinfo, name, alias)
+
+        # @@@ (Jon) something needs to be done here to handle aliases, probably
+
+        category = typeinfo.elem.get('category')
+        if category in ('struct', 'union'):
+            self.genStruct(typeinfo, name, alias)
--- Vulkan-Headers-1.2.156.orig/registry/vulkan-registry.pc.in
+++ Vulkan-Headers-1.2.156/registry/vulkan-registry.pc.in
@@ -0,0 +1,8 @@
+prefix=@CMAKE_INSTALL_PREFIX@
+datarootdir=${prefix}/share
+headersdir=${pc_sysrootdir}${prefix}/include
+pkgdatadir=${pc_sysrootdir}${datarootdir}/vulkan/registry
+
+Name: Vulkan Registry
+Description: Vulkan API registry file
+Version: 1.2.156
